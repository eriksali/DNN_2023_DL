{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVXx0TsN8vbTOzmMCGzlHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/gpu_random_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17ahZXHaocL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcki6APBjvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysIZamr8yr-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pLRrhqrozpUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setGPU\n",
        "!mkdir output\n",
        "##!unzip cifar10.zip\n",
        "!unzip smoothing.zip"
      ],
      "metadata": {
        "id": "R1_jaNgX8gYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##model=\"cifar10/resnet110/noise_0.25/checkpoint.pth.tar\"\n",
        "model=\"checkpoint.pth.tar\"\n",
        "output=\"output.txt\"\n",
        "!python smoothing/code/certify.py cifar10 $model 0.25 $output --skip 20 --batch 400"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfE4v5DcysC6",
        "outputId": "5f4ee68b-0756-4749-e8ff-2d05aaf1b8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "setGPU: Setting GPU to: 0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset_cache/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:01<00:00, 104817683.38it/s]\n",
            "Extracting ./dataset_cache/cifar-10-python.tar.gz to ./dataset_cache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nvf0VefXysGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYA1CxODmxZP",
        "outputId": "1163c19f-fd01-437f-a180-a1c5ad8e7099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  36.2M      0  0:00:40  0:00:40 --:--:-- 34.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "t_3g8-7IgXJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##!pip install adversarial-robustness-toolbox\n",
        "!pip install adversarial-robustness-toolbox --upgrade\n"
      ],
      "metadata": {
        "id": "X-Oc-sJqdXdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "xWqgWlUtgrKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "def f(x):\n",
        "    return model(x)\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((len(x), 10)).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn_like(x).to(device)\n",
        "        logits += f(x + noise)\n",
        "    return logits / n_samples\n",
        "\n",
        "\n",
        "class SmoothClassifier(nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 10)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "\n",
        "def certified_accuracy(model, test_loader, n_samples, sigma, alpha):\n",
        "    smooth_classifier = SmoothClassifier(f, sigma)\n",
        "    smooth_classifier = smooth_classifier.to(device)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Smooth the images\n",
        "        smoothed_logits = randomized_smoothing(images, model, n_samples, sigma)\n",
        "        smoothed_probs = F.softmax(smoothed_logits, dim=1)\n",
        "\n",
        "        # Compute the lower and upper bounds for each image\n",
        "        lower_bounds, upper_bounds = smoothed_probs.sort(dim=1)[0][:, -2:]\n",
        "        radius = (upper_bounds - lower_bounds).max(dim=1)[0]\n",
        "\n",
        "        # Check if the predicted label is within the radius\n",
        "        predicted_labels = smoothed_probs.argmax(dim=1)\n",
        "        distances = smoothed_probs.gather(1, labels.unsqueeze(1)).squeeze() - radius\n",
        "        correct += (distances > alpha).sum().item()\n",
        "        total += images.shape[0]\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    ]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "n_samples = 100\n",
        "sigma = 0.1\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "inMlUk-2gxHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the train and test sets\n",
        "train_dataset = datasets.ImageNet(root='imagenette2-320/train', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_dataset = datasets.ImageNet(root='imagenette2-320/val', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Set up the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define the model\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, sigma):\n",
        "    '''\n",
        "    Args:\n",
        "        x (torch.Tensor): input image tensor\n",
        "        model (torch.nn.Module): classifier model\n",
        "        n_samples (int): number of samples to use for smoothing\n",
        "        sigma (float): standard deviation of the Gaussian noise to add\n",
        "    Returns:\n",
        "        smooth_probs (torch.Tensor): smoothed class probabilities\n",
        "    '''\n",
        "\n",
        "    # Generate n_samples samples of Gaussian noise\n",
        "    noises = sigma * torch.randn(n_samples, *x.shape).to(device)\n",
        "\n",
        "    # Apply the classifier to the noisy images\n",
        "    logits = model(x.unsqueeze(0) + noises).squeeze(0)\n",
        "\n",
        "    # Compute the softmax of the logits\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "    # Average the class probabilities over the samples\n",
        "    smooth_probs = probs.mean(dim=0)\n",
        "\n",
        "    return smooth_probs\n",
        "\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    '''\n",
        "    Args:\n",
        "        model (torch.nn.Module): classifier model\n",
        "        test_loader (torch.utils.data.DataLoader): data loader for the test set\n",
        "        n_samples (int): number of samples to use for smoothing\n",
        "        sigma (float): standard deviation of the Gaussian noise to add\n",
        "    Returns:\n",
        "        accuracy (float): test set accuracy of the smoothed classifier\n",
        "    '''\n",
        "\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_probs = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed probabilities\n",
        "        preds = smoothed_probs.argmax(dim=-1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (preds == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "for i, (images, labels) in enumerate(test_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "# Generate adversarial examples using PGD\n",
        "adv_images = pgd_attack(images, labels, model, epsilon=0.03, alpha=0.01, iters=40)\n",
        "\n",
        "# Smooth the original and adversarial examples\n",
        "smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "smoothed_adv_images = randomized_smoothing(adv_images, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the models on the original and smoothed images\n",
        "clean_acc = evaluate(model, images, labels)\n",
        "smoothed_acc = evaluate_smoothed_classifier(model, images, n_samples, sigma)\n",
        "\n",
        "# Evaluate the models on the adversarial examples and smoothed adversarial examples\n",
        "adv_acc = evaluate(model, adv_images, labels)\n",
        "smoothed_adv_acc = evaluate_smoothed_classifier(model, adv_images, n_samples, sigma)\n",
        "\n",
        "# Print the results for this batch\n",
        "print(f'Batch {i+1}/{len(test_loader)}')\n",
        "print(f'Clean Accuracy: {clean_acc:.4f} | Smoothed Accuracy: {smoothed_acc:.4f}')\n",
        "print(f'Adversarial Accuracy: {adv_acc:.4f} | Smoothed Adversarial Accuracy: {smoothed_adv_acc:.4f}\\n')\n",
        "\n",
        "# Plot some of the original and smoothed images side by side\n",
        "if i == 0:\n",
        "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    for j in range(5):\n",
        "        axs[0][j].imshow(images[j].cpu().squeeze().permute(1, 2, 0))\n",
        "        axs[0][j].set_title(f'Original (Label: {labels[j].item()})')\n",
        "        axs[1][j].imshow(smoothed_images[j].cpu().squeeze().permute(1, 2, 0))\n",
        "        axs[1][j].set_title(f'Smoothed (Label: {torch.argmax(smoothed_images[j]).item()})')\n",
        "    plt.show()\n",
        "\n",
        "# Plot some of the adversarial and smoothed adversarial images side by side\n",
        "if i == 0:\n",
        "    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    for j in range(5):\n",
        "        axs[0][j].imshow(adv_images[j].cpu().squeeze().permute(1, 2, 0))\n",
        "        axs[0][j].set_title(f'Adversarial (Label: {labels[j].item()})')\n",
        "        axs[1][j].imshow(smoothed_adv_images[j].cpu().squeeze().permute(1, 2, 0))\n",
        "        axs[1][j].set_title(f'Smoothed Adversarial (Label: {torch.argmax(smoothed_adv_images[j]).item()})')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "JM8HNdgNfln1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "##from art.defences.transformer import RandomizedSmoothing\n",
        "from art.defences.trainer import RandomizedSmoothing\n",
        "import art\n",
        "art.config.set_framework('pytorch')\n",
        "\n",
        "\n",
        "# define the transforms\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                     std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "# load the dataset\n",
        "train_dataset = datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# define the data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# define the neural network\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "\n",
        "\n",
        "# define the adversarial attack\n",
        "epsilon = 0.1\n",
        "attack = FastGradientMethod(estimator=PyTorchClassifier(model=model, loss=torch.nn.CrossEntropyLoss()),\n",
        "                            eps=epsilon,\n",
        "                            norm=np.inf,\n",
        "                            targeted=False,\n",
        "                            batch_size=64)\n",
        "\n",
        "\n",
        "# define the adversarial attack\n",
        "epsilon = 0.1\n",
        "attack = FastGradientMethod(estimator=PyTorchClassifier(model=model, loss=torch.nn.CrossEntropyLoss()),\n",
        "                            eps=epsilon,\n",
        "                            norm=np.inf,\n",
        "                            targeted=False,\n",
        "                            batch_size=64)\n",
        "\n",
        "\n",
        "# evaluate the accuracy of the classifier without defense\n",
        "def evaluate_classifier(model, test_loader):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # make predictions\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # update accuracy\n",
        "        num_correct += (predicted == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# evaluate the accuracy of the classifier with defense\n",
        "def evaluate_defended_classifier(model, test_loader, defense):\n",
        "    model.eval()\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # apply defense\n",
        "        images_defended = defense(images)\n",
        "\n",
        "       \n",
        "# Define the smoothed classifier\n",
        "class SmoothClassifier(nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 10)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "# Define the defense\n",
        "def defense(x):\n",
        "    model.eval()\n",
        "    smoothed_classifier.eval()\n",
        "\n",
        "    # Apply the randomized smoothing defense\n",
        "    x = x.to(device)\n",
        "    x_smooth = randomized_smoothing(x, smoothed_classifier, n_samples, sigma)\n",
        "    x_defended = torch.argmax(x_smooth, dim=1)\n",
        "\n",
        "    return x_defended\n",
        "\n",
        "# Evaluate the accuracy of the defended model on the test set\n",
        "num_correct = 0\n",
        "num_total = 0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Apply defense\n",
        "    images_defended = defense(images)\n",
        "\n",
        "    # Compute the accuracy of the defended model\n",
        "    num_correct += (images_defended == labels).sum().item()\n",
        "    num_total += labels.size(0)\n",
        "\n",
        "test_accuracy = num_correct / num_total\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "o7YqmGGcdXg6",
        "outputId": "970b5847-ccca-4b9b-b56e-1347e047c4bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fee6bb5ea8dd>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyTorchClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m##from art.defences.transformer import RandomizedSmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomizedSmoothing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'RandomizedSmoothing' from 'art.defences.trainer' (/usr/local/lib/python3.9/dist-packages/art/defences/trainer/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model\n",
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def randomized_smoothing(x, f, n_samples, sigma):\n",
        "    logits = torch.zeros((len(x), 1000)).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn_like(x).to(device)\n",
        "        logits += f(x + noise)\n",
        "    return logits / n_samples\n",
        "\n",
        "# Define the smoothed classifier\n",
        "class SmoothClassifier(nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return randomized_smoothing(x, self.f, n_samples=100, sigma=self.sigma)\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "def test_smoothed_classifier(image, model, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples=100, sigma=sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples=100, sigma=sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "sigma = 0.1\n",
        "smooth_classifier = SmoothClassifier(model, sigma).to(device)\n",
        "test_accuracy = evaluate_smoothed_classifier(smooth_classifier, test_loader, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAx4iQQpcXLs",
        "outputId": "e322d5b8-0c18-4468-eaf7-d59704b22d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 10)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "# Define the model f\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def randomized_smoothing(x, model, n_samples, sigma):\n",
        "    smooth_classifier = SmoothClassifier(model, sigma)\n",
        "    return smooth_classifier(x)\n",
        "\n",
        "# Define the test set\n",
        "data_path = 'imagenette2/'\n",
        "test_dataset = datasets.ImageFolder(root=data_path + 'val',\n",
        "                                     transform=transforms.Compose([\n",
        "                                         transforms.Resize((224, 224)),\n",
        "                                         transforms.ToTensor()\n",
        "                                     ]))\n",
        "\n",
        "# Define the test loader\n",
        "batch_size = 128\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the subset of data for the certification\n",
        "subset_size = 1000\n",
        "subset_indices = np.random.choice(len(test_dataset), subset_size, replace=False)\n",
        "subset_dataset = Subset(test_dataset, subset_indices)\n",
        "\n",
        "# Define the subset loader\n",
        "subset_loader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the parameters for randomized smoothing\n",
        "sigma = 0.5\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "def evaluate_smoothed_classifier(model, loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Predict the labels for the smoothed images\n",
        "        predictions = smoothed_images.argmax(dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "        num_total += labels.shape[0]\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Define the certification function\n",
        "def certify(model, loader, sigma, n_samples, radius):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Compute the lower and upper bounds for each smoothed image\n",
        "        lower_bounds = smoothed_images.max(dim=1)[0] - radius\n",
        "        upper_bounds = smoothed_images.max(dim=1)[0]\n",
        "\n",
        "        # Determine which images are certified\n",
        "        certified = (lower_bounds > 0).float()\n",
        "\n",
        "        # Compute the accuracy of the certified classifier\n",
        "        num_correct += (certified * (labels == labels)).sum().item()\n",
        "        num_total += certified.sum().item()\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "# Define the radii to certify against\n",
        "radii = [0.1, 0.5, 1.0, 2.0, 4.0]\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
        "\n",
        "# Evaluate the smoothed classifier on the subset and compute the certified accuracy\n",
        "for radius in radii:\n",
        "    certified_accuracy = certify(model, subset_loader, sigma, n_samples, radius)\n",
        "    print(f'Certified Accuracy for r={radius}: {certified_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "E1VN8YsQbX3U",
        "outputId": "2280a73e-e7c6-437f-f770-ed5d655a8183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2f2e4616a062>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Evaluate the smoothed classifier on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_smoothed_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Accuracy: {test_accuracy:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2f2e4616a062>\u001b[0m in \u001b[0;36mevaluate_smoothed_classifier\u001b[0;34m(model, loader, n_samples, sigma)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Smooth the images using the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0msmoothed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Predict the labels for the smoothed images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2f2e4616a062>\u001b[0m in \u001b[0;36mrandomized_smoothing\u001b[0;34m(x, model, n_samples, sigma)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrandomized_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msmooth_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmoothClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msmooth_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Define the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2f2e4616a062>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (1000) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Define device for training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 64\n",
        "n_epochs = 2\n",
        "learning_rate = 0.001\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "alpha = 0.001\n",
        "\n",
        "# Define data preprocessing and augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the Imagenette2 dataset\n",
        "train_dataset = datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "num_train = len(train_dataset)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(0.2 * num_train))\n",
        "train_idx, val_idx = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "val_sampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "# Define the dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
        "model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "def randomized_smoothing(x, f, n_samples, sigma):\n",
        "    logits = torch.zeros((len(x), 10)).to(x.device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn_like(x).to(x.device)\n",
        "        logits += f(x + noise)\n",
        "    return logits / n_samples\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Train the model\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Add noise to the images\n",
        "        noise = sigma * torch.randn_like(images).to(device)\n",
        "        noisy_images = images + noise\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(noisy_images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track train loss and accuracy\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_acc += (predicted == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.sampler)\n",
        "    train_acc = train_acc / len(train_loader.sampler)\n",
        "    train_loss_list.append(train_loss)\n",
        "    train_acc_list.append(train_acc)\n",
        "\n",
        "    # Validate the model\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            #Smooth the images using the model\n",
        "            smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "            # Get the predicted labels from the smoothed images\n",
        "            smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "            # Compute the accuracy of the smoothed classifier\n",
        "            num_correct += (smoothed_labels == labels).sum().item()\n",
        "            num_total += labels.size(0)\n",
        "\n",
        "            # Compute the certified accuracy of the smoothed classifier\n",
        "            lower_bound, upper_bound = certify(model, images, n_samples, sigma, delta)\n",
        "            certified_acc += (smoothed_labels == labels) * (upper_bound >= delta)\n",
        "            \n",
        "    accuracy = num_correct / num_total\n",
        "    certified_accuracy = certified_acc.sum().item() / num_total\n",
        "\n",
        "print(f'Epoch {epoch}: Val Accuracy: {accuracy:.3f}, Certified Accuracy: {certified_accuracy:.3f}')\n",
        "\n",
        "# Save the model if it has the best certified accuracy so far\n",
        "if certified_accuracy > best_certified_accuracy:\n",
        "    best_certified_accuracy = certified_accuracy\n",
        "    torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "test_certified_accuracy = certify(model, test_loader, radius, n_samples, sigma, n_classes, n_iter)\n",
        "\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
        "print(f'Test Certified Accuracy: {test_certified_accuracy:.2f}')\n",
        "\n",
        " # Plot some examples of the original and smoothed images\n",
        "n_examples = 5\n",
        "images, labels = next(iter(val_loader))\n",
        "for i in range(n_examples):\n",
        "    image = images[i]\n",
        "    label = labels[i]\n",
        "\n",
        "    # Smooth the image using the best model\n",
        "    smoothed_image = randomized_smoothing(image.unsqueeze(0), model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title(f'Original (Label: {label.item()})')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed (Label: {smoothed_label})')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yj3mK-IjaOMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kHtDRURMaOQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model architecture\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        ##self.fc1 = torch.nn.Linear(64 * 32 * 32, 128)\n",
        "        self.fc1 = torch.nn.Linear(64 * 8 * 8, 128)\n",
        "\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "        \n",
        "        # Transpose the weight tensor of fc1\n",
        "        self.fc1.weight.data = self.fc1.weight.data.t()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create an instance of the model\n",
        "model = Model()\n",
        "\n",
        "# Define the number of samples to use for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the standard deviation of the noise to add for randomized smoothing\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the confidence level for certification\n",
        "delta = 1e-6\n",
        "\n",
        "# Define the radius to use for certification\n",
        "certified_radius = 0.1\n",
        "\n",
        "# Define the test dataset and data loader\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "def randomized_smoothing(x, f, n_samples, sigma):\n",
        "    logits = torch.zeros((len(x), 10)).to(x.device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn_like(x).to(x.device)\n",
        "        logits += f(x + noise)\n",
        "    return logits / n_samples\n",
        "\n",
        "def certify(model, x, n_samples, sigma, delta):\n",
        "    # Smooth the input image using the model\n",
        "    smoothed_logits = randomized_smoothing(x, model, n_samples, sigma)\n",
        "\n",
        "    # Compute the confidence radius\n",
        "    radius = np.sqrt(-2 * np.log(delta)) * sigma\n",
        "\n",
        "    # Compute the predicted label\n",
        "    predicted_label = torch.argmax(smoothed_logits, dim=1)\n",
        "\n",
        "    # Compute the number of predictions that differ from the predicted label\n",
        "    num_different_predictions = 0\n",
        "    for i in range(len(smoothed_logits)):\n",
        "        logits = smoothed_logits[i]\n",
        "        for j in range(len(logits)):\n",
        "            if j != predicted_label[i] and logits[j] >= smoothed_logits[i, predicted_label[i]] - radius[i]:\n",
        "                num_different_predictions += 1\n",
        "                break\n",
        "\n",
        "    # Compute the certified accuracy\n",
        "    certified_accuracy = 1 - (num_different_predictions / len(smoothed_logits))\n",
        "\n",
        "    return certified_accuracy\n",
        "\n",
        "def evaluate_certified_accuracy(model, test_loader, n_samples, sigma, radius):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    num_different_predictions = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Compute the logits of the smoothed images\n",
        "        smoothed_logits = model(smoothed_images)\n",
        "\n",
        "        # Compute the lower and upper bounds for each logit\n",
        "        lower_bounds = smoothed_logits.mean(dim=0) - certified_radius\n",
        "        upper_bounds = smoothed_logits.mean(dim=0) + certified_radius\n",
        "\n",
        "        # Compute the predicted label from the lower and upper bounds\n",
        "        predicted_labels = torch.argmax(lower_bounds)\n",
        "\n",
        "        # Check if the predicted label is the same for all smoothed images\n",
        "        if torch.all(torch.eq(predicted_labels, torch.argmax(upper_bounds))):\n",
        "            # Check if the predicted label matches the true label\n",
        "            if torch.eq(predicted_labels, labels):\n",
        "                num_correct += 1\n",
        "            num_total += 1\n",
        "        else:\n",
        "            num_different_predictions += 1\n",
        "\n",
        "    # Compute the certified accuracy\n",
        "    certified_accuracy = 1 - (num_different_predictions / len(test_loader.dataset))\n",
        "\n",
        "    return certified_accuracy\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "torchvision.datasets.CIFAR10(root='./data', train=False, transform=torchvision.transforms.ToTensor()),\n",
        "batch_size=100, shuffle=False)\n",
        "\n",
        "\n",
        "certified_radius = 0.1\n",
        "certified_accuracy = evaluate_certified_accuracy(model, test_loader, n_samples, sigma, certified_radius)\n",
        "print(f'Certified Accuracy with Radius {certified_radius:.2f}: {certified_accuracy:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "lLIEashPWune",
        "outputId": "00d2c134-2308-4904-8987-cfdcf07d5b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0c1557fc5eaa>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0mcertified_radius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mcertified_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_certified_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcertified_radius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Certified Accuracy with Radius {certified_radius:.2f}: {certified_accuracy:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0c1557fc5eaa>\u001b[0m in \u001b[0;36mevaluate_certified_accuracy\u001b[0;34m(model, test_loader, n_samples, sigma, radius)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Smooth the images using the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0msmoothed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Compute the logits of the smoothed images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0c1557fc5eaa>\u001b[0m in \u001b[0;36mrandomized_smoothing\u001b[0;34m(x, f, n_samples, sigma)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0c1557fc5eaa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x4096 and 128x4096)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model architecture\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64 * 32 * 32, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.conv1(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        x = torch.nn.functional.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64 * 32 * 32)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = Model()\n",
        "\n",
        "def randomized_smoothing(x, f, n_samples, sigma):\n",
        "    logits = torch.zeros((len(x), 10)).to(x.device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn_like(x).to(x.device)\n",
        "        logits += f(x + noise)\n",
        "    return logits / n_samples\n",
        "\n",
        "def certify(model, x, n_samples, sigma, delta):\n",
        "    # Smooth the input image using the model\n",
        "    smoothed_logits = randomized_smoothing(x, model, n_samples, sigma)\n",
        "\n",
        "    # Compute the confidence radius\n",
        "    radius = np.sqrt(-2 * np.log(delta)) * sigma\n",
        "\n",
        "    # Compute the predicted label\n",
        "    predicted_label = torch.argmax(smoothed_logits, dim=1)\n",
        "\n",
        "    # Compute the number of predictions that differ from the predicted label\n",
        "    num_different_predictions = 0\n",
        "    for i in range(len(smoothed_logits)):\n",
        "        logits = smoothed_logits[i]\n",
        "        for j in range(len(logits)):\n",
        "            if j != predicted_label[i] and logits[j] >= smoothed_logits[i, predicted_label[i]] - radius[i]:\n",
        "                num_different_predictions += 1\n",
        "                break\n",
        "\n",
        "    # Compute the certified accuracy\n",
        "    certified_accuracy = 1 - (num_different_predictions / len(smoothed_logits))\n",
        "\n",
        "    return certified_accuracy\n",
        "\n",
        "def evaluate_certified_accuracy(model, test_loader, n_samples, sigma, radius):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    num_different_predictions = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Compute the logits of the smoothed images\n",
        "        smoothed_logits = model(smoothed_images)\n",
        "\n",
        "        # Compute the lower and upper bounds for each logit\n",
        "        lower_bounds = smoothed_logits.mean(dim=0) - radius\n",
        "        upper_bounds = smoothed_logits.mean(dim=0) + radius\n",
        "\n",
        "        # Compute the predicted label from the lower and upper bounds\n",
        "        predicted_labels = torch.argmax(lower_bounds)\n",
        "\n",
        "        # Check if the predicted label is the same for all smoothed images\n",
        "        if torch.all(torch.eq(predicted_labels, torch.argmax(upper_bounds))):\n",
        "            # Check if the predicted label matches the true label\n",
        "            if torch.eq(predicted_labels, labels):\n",
        "                num_correct += 1\n",
        "            num_total += 1\n",
        "        else:\n",
        "            num_different_predictions += 1\n",
        "\n",
        "    # Compute the certified accuracy\n",
        "    certified_accuracy = 1 - (num_different_predictions / len(test_loader.dataset))\n",
        "\n",
        "    return certified_accuracy\n",
        "\n",
        "certified_radius = 0.1\n",
        "certified_accuracy = evaluate_certified_accuracy(model, test_loader, n_samples, sigma, certified_radius)\n",
        "print(f'Certified Accuracy with Radius {certified_radius:.2f}: {certified_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "XQJvUlO4TNiw",
        "outputId": "ffd24bbc-5503-4ee4-83b0-9d070e443065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ff023d93e0b4>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mcertified_radius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mcertified_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_certified_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcertified_radius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Certified Accuracy with Radius {certified_radius:.2f}: {certified_accuracy:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ff023d93e0b4>\u001b[0m in \u001b[0;36mevaluate_certified_accuracy\u001b[0;34m(model, test_loader, n_samples, sigma, radius)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Smooth the images using the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msmoothed_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_smoothing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Compute the logits of the smoothed images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ff023d93e0b4>\u001b[0m in \u001b[0;36mrandomized_smoothing\u001b[0;34m(x, f, n_samples, sigma)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ff023d93e0b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 65536]' is invalid for input of size 409600"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaBFUOiFTNnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ViJJE2f9TNsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = torch.nn.Linear(128 * 16 * 16, 256)\n",
        "        self.fc2 = torch.nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128 * 16 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the random smoothing function\n",
        "def random_smoothing(model, images, n_samples=10, epsilon=0.03):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        smooth_probs = torch.zeros((len(images), 10))\n",
        "        for i in range(n_samples):\n",
        "            smooth_probs += F.softmax(model(images + torch.randn_like(images) * epsilon), dim=1)\n",
        "        smooth_probs /= n_samples\n",
        "    return smooth_probs\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate(model, dataloader, n_samples=10, epsilon=0.03):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    total_certified = 0\n",
        "    for images, labels in tqdm(dataloader):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # Calculate the prediction of the model\n",
        "        preds = model(images)\n",
        "        # Calculate the accuracy of the model\n",
        "        total_correct += (preds.argmax(dim=1) == labels).sum().item()\n",
        "        total_samples += len(images)\n",
        "        # Calculate the certified accuracy of the model using random smoothing\n",
        "        smooth_probs = random_smoothing(model, images, n_samples, epsilon)\n",
        "        smoothed_preds = smooth_probs.argmax(dim=1)\n",
        "        certified_correct = ((smoothed_preds == preds.argmax(dim=1)) & (smooth_probs.max(dim=1).values >= 0.9)).sum().item()\n",
        "        total_certified += certified_correct\n",
        "    # Calculate and return the accuracies\n",
        "    accuracy = 100.0 * total_correct / total_samples\n",
        "    certified_accuracy = 100.0 * total_certified / total_samples\n",
        "    return accuracy, certified_accuracy\n",
        "\n",
        "# Define the data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = ImageFolder('imagenette2/train', transform=transform)\n",
        "test_data = ImageFolder('imagenette2/val', transform=transform)\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 8\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define the dataloaders for training and test data\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# Define the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "import torch.optim as optim\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the smoothing parameters\n",
        "epsilon = 0.1\n",
        "num_smooth = 50\n",
        "num_epochs = 2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to train mode\n",
        "    model.train()\n",
        "    \n",
        "    # Train the model on the training data\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Perform random smoothing\n",
        "        smoothed_images = torch.zeros_like(images)\n",
        "        for j in range(num_smooth):\n",
        "            smoothed_images += torch.randn_like(images) * epsilon\n",
        "        smoothed_images = smoothed_images.clamp(0, 1)\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass and compute the loss\n",
        "        outputs = model(smoothed_images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimize the weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    # Set the model to eval mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Evaluate the model on the test data\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Perform random smoothing\n",
        "        smoothed_images = torch.zeros_like(images)\n",
        "        for j in range(num_smooth):\n",
        "            smoothed_images += torch.randn_like(images) * epsilon\n",
        "        smoothed_images = smoothed_images.clamp(0, 1)\n",
        "        \n",
        "        # Forward pass and compute the predictions\n",
        "        outputs = model(smoothed_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # Compute the accuracy\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "    accuracy = 100 * correct / total\n",
        "    print('Epoch [{}/{}], Test Accuracy: {} %'.format(epoch+1, num_epochs, accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STigyX63e49k",
        "outputId": "0f7763d3-3fc1-453f-99e2-f307c9e67ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Test Accuracy: 9.859872611464969 %\n",
            "Epoch [2/2], Test Accuracy: 10.394904458598726 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Load the Imagenette2 dataset\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root='./imagenette2/train',\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root='./imagenette2/val',\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Define the model architecture\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and define the loss function and optimizer\n",
        "model = Model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "num_epochs = 2\n",
        "batch_size = 16\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Epoch [{}/{}], Test Accuracy: {} %'.format(epoch+1, num_epochs, test_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "OcVu2EP-dN-l",
        "outputId": "bd9522cf-4e07-4ca6-9190-a49ea89c1651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1f901533a55>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1024) to match target batch_size (16)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "num_classes = 10\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "'''\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "'''\n",
        "\n",
        "\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Reshape the output tensor\n",
        "            output = output.view(-1, num_classes)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Reshape the output tensor\n",
        "                output = output.view(-1, num_classes)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 2\n",
        "\n",
        "\n",
        "batch_size = 128 # or 128 if you retrain the model with a smaller batch size\n",
        "\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes*num_iterations).to(device)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        if num_iterations == 1:\n",
        "            total_score[:, :] += F.softmax(output, dim=1).repeat(1, num_classes)\n",
        "        else:\n",
        "            total_score[:, i*num_classes:(i+1)*num_classes] = F.softmax(output, dim=1)\n",
        "    \n",
        "    total_score = torch.cat([total_score[:, i*num_classes:(i+1)*num_classes] for i in range(num_iterations)], dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "9Jixfuj6Q7_T",
        "outputId": "21273c96-eb4f-4f92-e938-91f493d8ce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4494aa7d27cf>\u001b[0m in \u001b[0;36m<cell line: 188>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Compute the randomized smoothing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mrandomized_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mrandomized_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcert_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-4494aa7d27cf>\u001b[0m in \u001b[0;36mrandomized_score\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mtotal_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mtotal_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mtotal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (10) must match the existing size (1000) at non-singleton dimension 1.  Target sizes: [128, 10].  Tensor sizes: [128, 1000]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                ##margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=2)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 1\n",
        "\n",
        "\n",
        "batch_size = 128 # or 128 if you retrain the model with a smaller batch size\n",
        "\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "num_classes = 1000\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "'''def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations'''\n",
        "\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes*num_iterations).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score[:, i*num_classes:(i+1)*num_classes] += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "w7eZb35CPihy",
        "outputId": "d7807028-a863-461f-cfed-9c9b307a661d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e101457b8825>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Compute the randomized smoothing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mrandomized_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mrandomized_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcert_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e101457b8825>\u001b[0m in \u001b[0;36mrandomized_score\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mnoisy_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mtotal_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 1\n",
        "\n",
        "\n",
        "##batch_size = 10 # or 128 if you retrain the model with a smaller batch size\n",
        "batch_size = 1\n",
        "##test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# ...\n",
        "\n",
        "'''[cert_acc = 0.0\n",
        "for c in range(num_classes):\n",
        "    for i in range(len(test_loader.dataset)):\n",
        "        data, target = test_loader.dataset[i]\n",
        "        data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)\n",
        "        \n",
        "]'''\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "num_classes = 10\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "'''def randomized_score(images, labels):\n",
        "    ##total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    total_score = torch.zeros(images.size(0), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "'''\n",
        "\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(images.size(0), 1000).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score[:, :num_classes] / num_iterations\n",
        "\n",
        "\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "##eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "GOblCPwpKsI4",
        "outputId": "31940e0e-b875-43fc-df12-e57bc9de9d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-eebe7e21cecb>\u001b[0m in \u001b[0;36m<cell line: 143>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mcert_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcert_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcert_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcert_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mcert_radius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mcert_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcert_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mcert_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcert_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "'''# Load the training dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2', transform=transform)\n",
        "##trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)'''\n",
        "\n",
        "'''# Define the neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(7 * 7 * 512, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.pool(F.relu(self.conv6(x)))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.pool(F.relu(self.conv8(x)))\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x'''\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                ##margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=2)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 1\n",
        "\n",
        "\n",
        "batch_size = 128 # or 128 if you retrain the model with a smaller batch size\n",
        "'''input_data_batch = torch.utils.data.DataLoader(input_data, batch_size=batch_size, shuffle=True)\n",
        "target_data_batch = torch.utils.data.DataLoader(target_data, batch_size=batch_size, shuffle=True)\n",
        "'''\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "'''# Define the neural network model, optimizer, and loss function\n",
        "import torch.optim as optim\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    \n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "'''\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "num_classes = 10\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "'''# Train the model\n",
        "train(model, device, trainloader, optimizer, criterion)'''\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "BmaWNHr4IhmA",
        "outputId": "80bac3b7-b82e-4188-fa3d-38891d290e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ba0417846846>\u001b[0m in \u001b[0;36m<cell line: 191>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Compute the randomized smoothing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mrandomized_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mrandomized_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mcert_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ba0417846846>\u001b[0m in \u001b[0;36mrandomized_score\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mnoisy_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mtotal_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (1000) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageNet\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define dataset and data loader\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Define the transformation pipeline for the input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the test set\n",
        "test_dir = 'imagenette2/val/'\n",
        "test_dataset = ImageFolder(test_dir, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "'''\n",
        "dataset = ImageNet(root='./imagenette2', split='train', transform=data_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Train a ResNet50 model on ImageNet with Gaussian data augmentation\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "def train_model(model, optimizer, scheduler, dataloader, epochs=100, sigma=0.1):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Generate Gaussian noise\n",
        "            noise = sigma * torch.randn_like(inputs).to(device)\n",
        "\n",
        "            # Add noise to inputs\n",
        "            inputs_noisy = inputs + noise\n",
        "\n",
        "            # Compute logits\n",
        "            logits = model(inputs_noisy)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute running loss and accuracy\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predicted = torch.argmax(logits, dim=1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, optimizer, scheduler, dataloader, epochs=10, sigma=0.1)'''\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = sigma * torch.randn_like(x).to(device)\n",
        "            logits[i] = model(x + noise)\n",
        "        avg_logits = torch.mean(logits, dim=0)\n",
        "        return avg_logits\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = data_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "n_samples = 100\n",
        "sigma = 0.1\n",
        "\n",
        "logits = smoothed_classifier(img, model, n_samples, sigma)\n",
        "pred_label = torch.argmax(logits).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "oMB9m3ARmSj0",
        "outputId": "b6dad597-ea18-4f32-dd01-1b40d14d6580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5c618ab95541>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./imagenette2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m\"You need to download it externally and place it in {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./imagenette2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YFDbiG5mSnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kD1ZHokmSrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRkzVPwpjvev",
        "outputId": "940e661a-955a-4367-8036-dde7dcab1003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  42.1M      0  0:00:35  0:00:35 --:--:-- 41.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')\n"
      ],
      "metadata": {
        "id": "VLASyAu8kMEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='imagenette2/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "WvQZOk7nkSqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umLjX2l2kSvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/imagenette\n",
        "!pip install torchvision\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/imagenette/imagenette2-160.tgz', 'r:gz') as tar:\n",
        "    tar.extractall('/content/named_folders/imagenet-100')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "qlMiU66ggzrv",
        "outputId": "3d0e5a3c-9982-4895-fe94-1307a39893ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'imagenette' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c96e191eaec1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/imagenette/imagenette2-160.tgz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/named_folders/imagenet-100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/imagenette/imagenette2-160.tgz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "!mkdir imagenet\n",
        "# Define the path to the ImageNet data\n",
        "data_path = './imagenet/'\n",
        "\n",
        "# Define the subset of classes to use\n",
        "classes = ['cat', 'dog', 'bird']\n",
        "\n",
        "# Create a PyTorch dataset using the ImageFolder class\n",
        "dataset = datasets.ImageFolder(root=data_path, \n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                         std=[0.229, 0.224, 0.225])\n",
        "                                ]), \n",
        "                                target_transform=lambda x: classes.index(os.path.basename(os.path.dirname(x))))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset)-500, 500])\n"
      ],
      "metadata": {
        "id": "oMLdFl7-d-iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the ImageNet dataset\n",
        "train_dataset = datasets.ImageNet(root='imagenet', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset.download()\n"
      ],
      "metadata": {
        "id": "RL1scFrwd-qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='path/to/imagenet/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='path/to/imagenet/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "6Q7kAh-CdLaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "c_lFTgLKbEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, noise_std):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = noise_std * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "x = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float().div(255).to(device)\n",
        "\n",
        "\n",
        "n_samples = 100\n",
        "noise_std = 0.1\n",
        "\n",
        "y_smooth = randomized_smoothing(x, model, n_samples, noise_std)\n",
        "pred_label = torch.argmax(y_smooth).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "id": "PxkJUxMYapTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the standard deviation of the Gaussian noise\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the number of samples for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the batch size for evaluation\n",
        "batch_size = 64\n",
        "\n",
        "# Define the device to run the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the ImageNet dataset with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./imagenet/train', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train a ResNet50 model on the dataset\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "for epoch in range(10):\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "testset = torchvision.datasets.ImageFolder(root='./imagenet/val', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "total, correct = 0, 0\n",
        "for i, (inputs, labels) in enumerate(testloader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = smoothed_classifier(inputs, model, n_samples, sigma)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the smoothed classifier on the test set: %.2f%%' % accuracy)\n"
      ],
      "metadata": {
        "id": "cixok1QycKiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}