{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi2Hv6qTVHeiHsSlnDqS3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/Input-dependent-certification_random_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17ahZXHaocL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcki6APBjvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYA1CxODmxZP",
        "outputId": "9c3feece-16d1-47b8-df1c-efd76ff2fbf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  48.4M      0  0:00:30  0:00:30 --:--:-- 47.5M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageNet\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define dataset and data loader\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset = ImageNet(root='./imagenette2', split='train', transform=data_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Train a ResNet50 model on ImageNet with Gaussian data augmentation\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "def train_model(model, optimizer, scheduler, dataloader, epochs=100, sigma=0.1):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Generate Gaussian noise\n",
        "            noise = sigma * torch.randn_like(inputs).to(device)\n",
        "\n",
        "            # Add noise to inputs\n",
        "            inputs_noisy = inputs + noise\n",
        "\n",
        "            # Compute logits\n",
        "            logits = model(inputs_noisy)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute running loss and accuracy\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predicted = torch.argmax(logits, dim=1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, optimizer, scheduler, dataloader, epochs=10, sigma=0.1)\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = sigma * torch.randn_like(x).to(device)\n",
        "            logits[i] = model(x + noise)\n",
        "        avg_logits = torch.mean(logits, dim=0)\n",
        "        return avg_logits\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = data_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "n_samples = 100\n",
        "sigma = 0.1\n",
        "\n",
        "logits = smoothed_classifier(img, model, n_samples, sigma)\n",
        "pred_label = torch.argmax(logits).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "oMB9m3ARmSj0",
        "outputId": "b6dad597-ea18-4f32-dd01-1b40d14d6580"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5c618ab95541>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./imagenette2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m\"You need to download it externally and place it in {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./imagenette2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YFDbiG5mSnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kD1ZHokmSrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRkzVPwpjvev",
        "outputId": "940e661a-955a-4367-8036-dde7dcab1003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  42.1M      0  0:00:35  0:00:35 --:--:-- 41.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')\n"
      ],
      "metadata": {
        "id": "VLASyAu8kMEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='imagenette2/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "WvQZOk7nkSqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umLjX2l2kSvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/imagenette\n",
        "!pip install torchvision\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/imagenette/imagenette2-160.tgz', 'r:gz') as tar:\n",
        "    tar.extractall('/content/named_folders/imagenet-100')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "qlMiU66ggzrv",
        "outputId": "3d0e5a3c-9982-4895-fe94-1307a39893ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'imagenette' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c96e191eaec1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/imagenette/imagenette2-160.tgz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/named_folders/imagenet-100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/imagenette/imagenette2-160.tgz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "!mkdir imagenet\n",
        "# Define the path to the ImageNet data\n",
        "data_path = './imagenet/'\n",
        "\n",
        "# Define the subset of classes to use\n",
        "classes = ['cat', 'dog', 'bird']\n",
        "\n",
        "# Create a PyTorch dataset using the ImageFolder class\n",
        "dataset = datasets.ImageFolder(root=data_path, \n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                         std=[0.229, 0.224, 0.225])\n",
        "                                ]), \n",
        "                                target_transform=lambda x: classes.index(os.path.basename(os.path.dirname(x))))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset)-500, 500])\n"
      ],
      "metadata": {
        "id": "oMLdFl7-d-iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the ImageNet dataset\n",
        "train_dataset = datasets.ImageNet(root='imagenet', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset.download()\n"
      ],
      "metadata": {
        "id": "RL1scFrwd-qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='path/to/imagenet/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='path/to/imagenet/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "6Q7kAh-CdLaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "c_lFTgLKbEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, noise_std):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = noise_std * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "x = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float().div(255).to(device)\n",
        "\n",
        "\n",
        "n_samples = 100\n",
        "noise_std = 0.1\n",
        "\n",
        "y_smooth = randomized_smoothing(x, model, n_samples, noise_std)\n",
        "pred_label = torch.argmax(y_smooth).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "id": "PxkJUxMYapTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the standard deviation of the Gaussian noise\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the number of samples for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the batch size for evaluation\n",
        "batch_size = 64\n",
        "\n",
        "# Define the device to run the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the ImageNet dataset with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./imagenet/train', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train a ResNet50 model on the dataset\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "for epoch in range(10):\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "testset = torchvision.datasets.ImageFolder(root='./imagenet/val', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "total, correct = 0, 0\n",
        "for i, (inputs, labels) in enumerate(testloader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = smoothed_classifier(inputs, model, n_samples, sigma)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the smoothed classifier on the test set: %.2f%%' % accuracy)\n"
      ],
      "metadata": {
        "id": "cixok1QycKiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}