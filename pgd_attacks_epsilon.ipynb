{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/pgd_attacks_epsilon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17ahZXHaocL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import norm\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "# Download ResNet18 and set the pretrained parameter to True\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# Set up the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the ResNet18 model and optimizer\n",
        "##net = ResNet18()\n",
        "net = resnet18\n",
        "net = net.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Train the ResNet18 model\n",
        "for epoch in range(1):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    train_acc = 100. * correct / total\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    test_acc = 100. * correct / total\n",
        "\n",
        "    print('Epoch [%d/%d] Train Loss: %.3f Train Acc: %.3f Test Loss: %.3f Test Acc: %.3f' % (\n",
        "        epoch + 1, 200, train_loss, train_acc, test_loss, test_acc))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "def certify_sample(model, x, y_pred, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Computes the certified radius for a single input using randomized smoothing.\n",
        "\n",
        "    Arguments:\n",
        "        model: A PyTorch model to certify.\n",
        "        x: The input tensor to certify.\n",
        "        y_pred: The model's predicted output for the input x.\n",
        "        sigma: The standard deviation of the Gaussian noise to add to the input during smoothing.\n",
        "        num_samples: The number of samples to use for smoothing.\n",
        "        beta: The confidence level for the certification, which determines the radius of the certified set.\n",
        "\n",
        "    Returns:\n",
        "        The certified radius for the input x.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Compute the perturbation standard deviation for the given sigma and beta\n",
        "    delta = sigma * math.sqrt(num_samples - 1) * norm.ppf(1 - beta / 2)\n",
        "\n",
        "    # Compute the smoothed predictions for the input x\n",
        "    y_smooth = torch.zeros((num_samples,) + y_pred.shape, dtype=y_pred.dtype, device=y_pred.device)\n",
        "    for i in range(num_samples):\n",
        "        noise = torch.randn_like(x) * sigma\n",
        "        y_smooth[i] = model(x + noise)\n",
        "    y_smooth = y_smooth.softmax(dim=-1)\n",
        "\n",
        "    # Compute the predicted class probabilities for the smoothed predictions\n",
        "    y_bar = y_smooth.mean(dim=0)\n",
        "\n",
        "    # Compute the distance between the original predictions and the smoothed predictions\n",
        "    d = (y_pred.softmax(dim=-1) - y_bar).norm(p=2)\n",
        "\n",
        "    # Compute the certified radius\n",
        "    r = delta + d.item()\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "def certify(model, dataset, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Computes certified radii for a PyTorch model using randomized smoothing.\n",
        "\n",
        "    Arguments:\n",
        "        model: A PyTorch model to certify.\n",
        "        dataset: A PyTorch dataset containing the data to certify.\n",
        "        sigma: The standard deviation of the Gaussian noise to add to the input during smoothing.\n",
        "        num_samples: The number of samples to use for smoothing.\n",
        "        beta: The confidence level for the certification, which determines the radius of the certified set.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array of certified radii, one for each input in the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Determine the size of the dataset\n",
        "    n = len(dataset)\n",
        "\n",
        "    # Compute the certified radii for each input in the dataset\n",
        "    certified_radii = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        x, y = dataset[i]\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        y_pred = model(x)\n",
        "        r = certify_sample(model, x, y_pred, sigma, num_samples, beta)\n",
        "        certified_radii[i] = r\n",
        "\n",
        "    return certified_radii\n",
        "\n",
        "\n",
        "# Generate the certified radii for the ResNet18 model on CIFAR-10\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Load the CIFAR-10 test dataset\n",
        "testset = CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "# Create a data loader for the test dataset\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the standard deviation, number of samples, and confidence level for certification\n",
        "sigma = 0.25\n",
        "num_samples = 100\n",
        "beta = 0.001\n",
        "\n",
        "# Call the certify function with the test dataset and the certification parameters\n",
        "certified_radii = certify(net, testset, sigma, num_samples, beta)\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "def pgd_attack(model, images, labels, eps, alpha, iters, device):\n",
        "    \"\"\"\n",
        "    PGD attack function for adversarial examples generation\n",
        "\n",
        "    Args:\n",
        "    - model: the neural network model to attack\n",
        "    - images: the clean images to be attacked\n",
        "    - labels: the true labels of the images\n",
        "    - eps: the maximum L-infinity norm of the perturbations\n",
        "    - alpha: the step size of each iteration of the attack\n",
        "    - iters: the number of iterations of the attack\n",
        "    - device: the device to run the attack on (e.g., 'cuda' for GPU)\n",
        "\n",
        "    Returns:\n",
        "    - adv_images: the generated adversarial examples\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Generate random perturbations\n",
        "    delta = torch.zeros_like(images).uniform_(-eps, eps)\n",
        "    delta = torch.clamp(images + delta, min=0, max=1) - images\n",
        "    delta.requires_grad = True\n",
        "\n",
        "    for i in range(iters):\n",
        "        # Forward pass\n",
        "        outputs = model(images + delta)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Generate adversarial perturbation\n",
        "        with torch.no_grad():\n",
        "            delta += alpha * delta.grad.sign()\n",
        "            delta = torch.clamp(delta, min=-eps, max=eps)\n",
        "            delta = torch.clamp(images + delta, min=0, max=1) - images\n",
        "            delta.requires_grad = True\n",
        "\n",
        "    # Return the adversarial examples\n",
        "    adv_images = torch.clamp(images + delta, min=0, max=1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "\n",
        "epsilons = [0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32]\n",
        "for epsilon in epsilons:\n",
        "    print(f\"PGD Attack with epsilon={epsilon}\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        adv_inputs = pgd_attack(net, inputs, targets, epsilon, 0.01, 2, 1) # Use PGD to generate adversarial examples\n",
        "        outputs = net(adv_inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    acc = 100. * correct / total\n",
        "    print(f\"Accuracy under PGD attack with epsilon {epsilon} : {acc:.2f} %\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "URm14yLw9Rge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##certified_radii = certify(net, testset, sigma, num_samples, beta)\n",
        "print(certified_radii)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIss8-TPgxPV",
        "outputId": "280eb92b-fced-4d25-d133-e4af9cc9237b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.35881546 8.29968126 8.38004795 ... 8.31472488 8.34391244 8.35219914]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def certify_sample(model, x, y_pred, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Computes the certified radius for a single input using randomized smoothing.\n",
        "\n",
        "    Arguments:\n",
        "        model: A PyTorch model to certify.\n",
        "        x: The input tensor to certify.\n",
        "        y_pred: The model's predicted output for the input x.\n",
        "        sigma: The standard deviation of the Gaussian noise to add to the input during smoothing.\n",
        "        num_samples: The number of samples to use for smoothing.\n",
        "        beta: The confidence level for the certification, which determines the radius of the certified set.\n",
        "\n",
        "    Returns:\n",
        "        The certified radius for the input x.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Compute the perturbation standard deviation for the given sigma and beta\n",
        "    delta = sigma * math.sqrt(num_samples - 1) * norm.ppf(1 - beta / 2)\n",
        "\n",
        "    # Compute the smoothed predictions for the input x\n",
        "    y_smooth = torch.zeros((num_samples,) + y_pred.shape, dtype=y_pred.dtype, device=y_pred.device)\n",
        "    for i in range(num_samples):\n",
        "        noise = torch.randn_like(x) * sigma\n",
        "        y_smooth[i] = model(x + noise)\n",
        "    y_smooth = y_smooth.softmax(dim=-1)\n",
        "\n",
        "    # Compute the predicted class probabilities for the smoothed predictions\n",
        "    y_bar = y_smooth.mean(dim=0)\n",
        "\n",
        "    # Compute the distance between the original predictions and the smoothed predictions\n",
        "    d = (y_pred.softmax(dim=-1) - y_bar).norm(p=2)\n",
        "\n",
        "    # Compute the certified radius\n",
        "    r = delta + d.item()\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "def certify(model, dataset, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Computes certified radii for a PyTorch model using randomized smoothing.\n",
        "\n",
        "    Arguments:\n",
        "        model: A PyTorch model to certify.\n",
        "        dataset: A PyTorch dataset containing the data to certify.\n",
        "        sigma: The standard deviation of the Gaussian noise to add to the input during smoothing.\n",
        "        num_samples: The number of samples to use for smoothing.\n",
        "        beta: The confidence level for the certification, which determines the radius of the certified set.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array of certified radii, one for each input in the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Determine the size of the dataset\n",
        "    n = len(dataset)\n",
        "\n",
        "    # Compute the certified radii for each input in the dataset\n",
        "    certified_radii = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        x, y = dataset[i]\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        y_pred = model(x)\n",
        "        r = certify_sample(model, x, y_pred, sigma, num_samples, beta)\n",
        "        certified_radii[i] = r\n",
        "\n",
        "    return certified_radii\n",
        "\n",
        "\n",
        "# Generate the certified radii for the ResNet18 model on CIFAR-10\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Load the CIFAR-10 test dataset\n",
        "testset = CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "# Create a data loader for the test dataset\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the standard deviation, number of samples, and confidence level for certification\n",
        "sigma = 0.25\n",
        "num_samples = 100\n",
        "beta = 0.001\n",
        "\n",
        "# Call the certify function with the test dataset and the certification parameters\n",
        "certified_radii = certify(net, testset, sigma, num_samples, beta)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the ResNet18 model against PGD attacks\n",
        "epsilons = [0.005, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32]\n",
        "for epsilon in epsilons:\n",
        "    print(f\"PGD Attack with epsilon={epsilon}\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        adv_inputs = pgd_attack(net, inputs, targets, epsilon, 20, 0.01, device=1) # Use PGD to generate adversarial examples\n",
        "        outputs = net(adv_inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / total\n",
        "print(f\"Accuracy under PGD attack with epsilon {epsilon} : {acc:.2f} %\")\n"
      ],
      "metadata": {
        "id": "zKToztVhGSay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import norm\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pgd_attack(model, images, labels, eps, alpha, iters, device):\n",
        "    \"\"\"\n",
        "    PGD attack function for adversarial examples generation\n",
        "\n",
        "    Args:\n",
        "    - model: the neural network model to attack\n",
        "    - images: the clean images to be attacked\n",
        "    - labels: the true labels of the images\n",
        "    - eps: the maximum L-infinity norm of the perturbations\n",
        "    - alpha: the step size of each iteration of the attack\n",
        "    - iters: the number of iterations of the attack\n",
        "    - device: the device to run the attack on (e.g., 'cuda' for GPU)\n",
        "\n",
        "    Returns:\n",
        "    - adv_images: the generated adversarial examples\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Generate random perturbations\n",
        "    delta = torch.zeros_like(images).uniform_(-eps, eps)\n",
        "    delta = torch.clamp(images + delta, min=0, max=1) - images\n",
        "    delta.requires_grad = True\n",
        "\n",
        "    for i in range(iters):\n",
        "        # Forward pass\n",
        "        outputs = model(images + delta)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Generate adversarial perturbation\n",
        "        with torch.no_grad():\n",
        "            delta += alpha * delta.grad.sign()\n",
        "            delta = torch.clamp(delta, min=-eps, max=eps)\n",
        "            delta = torch.clamp(images + delta, min=0, max=1) - images\n",
        "            delta.requires_grad = True\n",
        "\n",
        "    # Return the adversarial examples\n",
        "    adv_images = torch.clamp(images + delta, min=0, max=1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "\n",
        "epsilons = [0.005, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32]\n",
        "for epsilon in epsilons:\n",
        "    print(f\"PGD Attack with epsilon={epsilon}\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        adv_inputs = pgd_attack(net, inputs, targets, epsilon, 0.01, 2, 1) # Use PGD to generate adversarial examples\n",
        "        outputs = net(adv_inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    acc = 100. * correct / total\n",
        "    print(f\"Accuracy under PGD attack with epsilon {epsilon} : {acc:.2f} %\")\n"
      ],
      "metadata": {
        "id": "UQYjT6oEF1QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446d8c7f-bf59-4aa4-c322-57014664d353"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD Attack with epsilon=0.005\n",
            "Accuracy under PGD attack with epsilon 0.005 : 13.47 %\n",
            "PGD Attack with epsilon=0.01\n",
            "Accuracy under PGD attack with epsilon 0.01 : 11.91 %\n",
            "PGD Attack with epsilon=0.02\n",
            "Accuracy under PGD attack with epsilon 0.02 : 10.39 %\n",
            "PGD Attack with epsilon=0.04\n",
            "Accuracy under PGD attack with epsilon 0.04 : 9.58 %\n",
            "PGD Attack with epsilon=0.08\n",
            "Accuracy under PGD attack with epsilon 0.08 : 9.17 %\n",
            "PGD Attack with epsilon=0.16\n",
            "Accuracy under PGD attack with epsilon 0.16 : 8.77 %\n",
            "PGD Attack with epsilon=0.32\n",
            "Accuracy under PGD attack with epsilon 0.32 : 8.00 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import norm\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pgd_attack(model, images, labels, eps, alpha, iters, device):\n",
        "    \"\"\"\n",
        "    PGD attack function for adversarial examples generation\n",
        "\n",
        "    Args:\n",
        "    - model: the neural network model to attack\n",
        "    - images: the clean images to be attacked\n",
        "    - labels: the true labels of the images\n",
        "    - eps: the maximum L-infinity norm of the perturbations\n",
        "    - alpha: the step size of each iteration of the attack\n",
        "    - iters: the number of iterations of the attack\n",
        "    - device: the device to run the attack on (e.g., 'cuda' for GPU)\n",
        "\n",
        "    Returns:\n",
        "    - adv_images: the generated adversarial examples\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Generate random perturbations\n",
        "    delta = torch.zeros_like(images).uniform_(-eps, eps)\n",
        "    delta = torch.clamp(images + delta, min=0, max=1) - images\n",
        "    delta.requires_grad = True\n",
        "\n",
        "    for i in range(iters):\n",
        "        # Forward pass\n",
        "        outputs = model(images + delta)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Generate adversarial perturbation\n",
        "        with torch.no_grad():\n",
        "            delta += alpha * delta.grad.sign()\n",
        "            delta = torch.clamp(delta, min=-eps, max=eps)\n",
        "            delta = torch.clamp(images + delta, min=0, max=1) - images\n",
        "            delta.requires_grad = True\n",
        "\n",
        "    # Return the adversarial examples\n",
        "    adv_images = torch.clamp(images + delta, min=0, max=1)\n",
        "\n",
        "    return adv_images\n",
        "\n",
        "\n",
        "epsilons = [0.0005, 0.001, 0.002]\n",
        "for epsilon in epsilons:\n",
        "    print(f\"PGD Attack with epsilon={epsilon}\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        adv_inputs = pgd_attack(net, inputs, targets, epsilon, 0.01, 2, 1) # Use PGD to generate adversarial examples\n",
        "        outputs = net(adv_inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    acc = 100. * correct / total\n",
        "    print(f\"Accuracy under PGD attack with epsilon {epsilon} : {acc:.2f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twpYiUMTsrw5",
        "outputId": "d95c446e-0bf8-4e3c-8f73-74a37734bfff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGD Attack with epsilon=0.0005\n",
            "Accuracy under PGD attack with epsilon 0.0005 : 14.99 %\n",
            "PGD Attack with epsilon=0.001\n",
            "Accuracy under PGD attack with epsilon 0.001 : 14.80 %\n",
            "PGD Attack with epsilon=0.002\n",
            "Accuracy under PGD attack with epsilon 0.002 : 14.44 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "##from models import ResNet18 # Import your ResNet18 model\n",
        "##from certify import certify # Import the certify function from the provided code\n",
        "##from attacks import pgd_attack # Import the PGD attack function from the provided code\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Download ResNet18 and set the pretrained parameter to True\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "# Set up the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the ResNet18 model and optimizer\n",
        "##net = ResNet18()\n",
        "net = resnet18\n",
        "net = net.to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Train the ResNet18 model\n",
        "for epoch in range(2):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    train_acc = 100. * correct / total\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    test_acc = 100. * correct / total\n",
        "\n",
        "    print('Epoch [%d/%d] Train Loss: %.3f Train Acc: %.3f Test Loss: %.3f Test Acc: %.3f' % (\n",
        "        epoch + 1, 200, train_loss, train_acc, test_loss, test_acc))\n",
        "\n",
        "###############################################################################\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import norm\n",
        "\n",
        "'''def certify(model, x, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Compute the certified radius for a given input using randomized smoothing.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): the neural network model to certify\n",
        "        x (Tensor): the input image for which to compute the certified radius\n",
        "        sigma (float): the standard deviation of the Gaussian noise used for randomized smoothing\n",
        "        num_samples (int): the number of samples used to estimate the robustness of the smoothed classifier\n",
        "        beta (float): the confidence level of the certification\n",
        "\n",
        "    Returns:\n",
        "        float: the certified radius of the input\n",
        "    \"\"\"\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Compute the standard deviation of the noise after normalization\n",
        "    sigma_norm = sigma / np.sqrt(np.prod(x.shape[1:]))\n",
        "\n",
        "    # Generate a batch of samples from the input with Gaussian noise\n",
        "    x_samples = torch.tensor(\n",
        "        np.random.normal(loc=x, scale=sigma_norm, size=(num_samples, *x.shape)).astype(np.float32)\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the noisy samples\n",
        "    with torch.no_grad():\n",
        "        logits = model(x_samples)\n",
        "\n",
        "    # Compute the maximum logit across the samples\n",
        "    max_logits, _ = logits.max(dim=1)\n",
        "\n",
        "    # Compute the threshold for the certified radius\n",
        "    threshold = norm.ppf(beta) * max_logits.std() + max_logits.mean()\n",
        "\n",
        "    # Compute the certified radius\n",
        "    radius = sigma * norm.ppf(beta) / (max_logits - threshold).abs().max().sqrt().item()\n",
        "\n",
        "    return radius'''\n",
        "\n",
        "\n",
        "sigma = 0.25\n",
        "num_samples = 100\n",
        "beta = 0.1\n",
        "\n",
        "# Compute the certified radius for the first image in the test set\n",
        "x, y = next(iter(testloader))\n",
        "x, y = x.to(device), y.to(device)\n",
        "radius = certify(resnet18, x[0], sigma, num_samples, beta)\n",
        "print(f\"Certified radius for image 0: {radius:.4f}\")\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pgd_attack(model, x, y, epsilon, alpha, num_iter):\n",
        "    \"\"\"\n",
        "    PGD attack on a neural network model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): the neural network model to attack\n",
        "        x (Tensor): the input image to attack\n",
        "        y (Tensor): the true label of the input image\n",
        "        epsilon (float): the maximum perturbation allowed\n",
        "        alpha (float): the step size of the attack\n",
        "        num_iter (int): the number of iterations of the attack\n",
        "\n",
        "    Returns:\n",
        "        Tensor: the perturbed image\n",
        "    \"\"\"\n",
        "    # Create a copy of the input image for the attack\n",
        "    x_adv = x.clone().detach()\n",
        "\n",
        "    # Set the image to require gradient\n",
        "    x_adv.requires_grad = True\n",
        "\n",
        "    # PGD attack loop\n",
        "    for i in range(num_iter):\n",
        "        # Zero out the gradient\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass to get the logits\n",
        "        logits = model(x_adv)\n",
        "\n",
        "        # Compute the loss as the cross-entropy between the logits and the true label\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "\n",
        "        # Backward pass to compute the gradient\n",
        "        loss.backward()\n",
        "\n",
        "        # Compute the sign of the gradient\n",
        "        grad = x_adv.grad.detach().sign()\n",
        "\n",
        "        # Update the perturbed image\n",
        "        x_adv = x_adv + alpha * grad\n",
        "\n",
        "        # Clip the perturbation to epsilon\n",
        "        x_adv = torch.max(torch.min(x_adv, x + epsilon), x - epsilon)\n",
        "\n",
        "        # Clamp the perturbed image to [0, 1]\n",
        "        x_adv = torch.clamp(x_adv, 0, 1)\n",
        "\n",
        "        # Detach the gradient to prevent it from accumulating\n",
        "        x_adv = x_adv.detach()\n",
        "\n",
        "    return x_adv\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "def certify_sample(model, x, y_pred, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Computes the certified radius for a single input using randomized smoothing.\n",
        "\n",
        "    Arguments:\n",
        "        model: A PyTorch model to certify.\n",
        "        x: The input tensor to certify.\n",
        "        y_pred: The model's predicted output for the input x.\n",
        "        sigma: The standard deviation of the Gaussian noise to add to the input during smoothing.\n",
        "        num_samples: The number of samples to use for smoothing.\n",
        "        beta: The confidence level for the certification, which determines the radius of the certified set.\n",
        "\n",
        "    Returns:\n",
        "        The certified radius for the input x.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Compute the perturbation standard deviation for the given sigma and beta\n",
        "    delta = sigma * math.sqrt(num_samples - 1) * norm.ppf(1 - beta / 2)\n",
        "\n",
        "    # Compute the smoothed predictions for the input x\n",
        "    y_smooth = torch.zeros((num_samples,) + y_pred.shape, dtype=y_pred.dtype, device=y_pred.device)\n",
        "    for i in range(num_samples):\n",
        "        noise = torch.randn_like(x) * sigma\n",
        "        y_smooth[i] = model(x + noise)\n",
        "    y_smooth = y_smooth.softmax(dim=-1)\n",
        "\n",
        "    # Compute the predicted class probabilities for the smoothed predictions\n",
        "    y_bar = y_smooth.mean(dim=0)\n",
        "\n",
        "    # Compute the distance between the original predictions and the smoothed predictions\n",
        "    d = (y_pred.softmax(dim=-1) - y_bar).norm(p=2)\n",
        "\n",
        "    # Compute the certified radius\n",
        "    r = delta + d.item()\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "def certify(model, dataset, sigma, num_samples, beta):\n",
        "    \"\"\"\n",
        "    Computes certified radii for a PyTorch model using randomized smoothing.\n",
        "\n",
        "    Arguments:\n",
        "        model: A PyTorch model to certify.\n",
        "        dataset: A PyTorch dataset containing the data to certify.\n",
        "        sigma: The standard deviation of the Gaussian noise to add to the input during smoothing.\n",
        "        num_samples: The number of samples to use for smoothing.\n",
        "        beta: The confidence level for the certification, which determines the radius of the certified set.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array of certified radii, one for each input in the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Determine the size of the dataset\n",
        "    n = len(dataset)\n",
        "\n",
        "    # Compute the certified radii for each input in the dataset\n",
        "    certified_radii = np.zeros(n)\n",
        "    for i in range(n):\n",
        "        x, y = dataset[i]\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        y_pred = model(x)\n",
        "        r = certify_sample(model, x, y_pred, sigma, num_samples, beta)\n",
        "        certified_radii[i] = r\n",
        "\n",
        "    return certified_radii\n",
        "\n",
        "\n",
        "# Generate the certified radii for the ResNet18 model on CIFAR-10\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Load the CIFAR-10 test dataset\n",
        "testset = CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
        "\n",
        "# Create a data loader for the test dataset\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the standard deviation, number of samples, and confidence level for certification\n",
        "sigma = 0.25\n",
        "num_samples = 100\n",
        "beta = 0.001\n",
        "\n",
        "# Call the certify function with the test dataset and the certification parameters\n",
        "certified_radii = certify(net, testset, sigma, num_samples, beta)\n",
        "\n",
        "# Evaluate the ResNet18 model against PGD attacks\n",
        "epsilons = [0.005, 0.01, 0.02, 0.04, 0.08, 0.16, 0.32]\n",
        "for epsilon in epsilons:\n",
        "    print(f\"PGD Attack with epsilon={epsilon}\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.eval()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        adv_inputs = pgd_attack(net, inputs, targets, epsilon, 20, 0.01, device=1) # Use PGD to generate adversarial examples\n",
        "        outputs = net(adv_inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / total\n",
        "print(f\"Accuracy under PGD attack with epsilon {epsilon} : {acc:.2f} %\")\n"
      ],
      "metadata": {
        "id": "PT2nkpg9p2y6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "42649b3c-a050-44c0-a8e0-4115fd243e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 60.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49929596.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch [1/200] Train Loss: 1012.324 Train Acc: 20.586 Test Loss: 154.123 Test Acc: 30.360\n",
            "Epoch [2/200] Train Loss: 675.178 Train Acc: 34.890 Test Loss: 129.226 Test Acc: 39.350\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-02939eef9701>\u001b[0m in \u001b[0;36m<cell line: 126>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcertify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Certified radius for image 0: {radius:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'certify' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcki6APBjvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRkzVPwpjvev",
        "outputId": "2836dd1a-28c7-410a-8807-270da56b395e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  41.3M      0  0:00:35  0:00:35 --:--:-- 42.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')\n"
      ],
      "metadata": {
        "id": "VLASyAu8kMEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='imagenette2/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "##smooth_classifier = SmoothClassifier(model, sigma)\n",
        "\n",
        "\n",
        "##num_epochs = 10\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "'''sigma = 0.1\n",
        "n_samples = 100\n",
        "'''\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "'''# Get a batch of test images\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# Pass the first image in the batch to the smoothed classifier test function\n",
        "test_smoothed_classifier(images[0], model, n_samples, sigma)\n",
        "\n",
        "# Load an example image from the test set\n",
        "x, _ = next(iter(test_loader))\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)'''\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "WvQZOk7nkSqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "b866f333-0bfd-4ead-f40d-b75963939c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 2.506537323062484\n",
            "Epoch 2: Loss = 1.6559423812337823\n",
            "Epoch 3: Loss = 1.3265508791884861\n",
            "Epoch 4: Loss = 0.9965532989920797\n",
            "Epoch 5: Loss = 0.6760593493645256\n",
            "Epoch 6: Loss = 0.3954530240514794\n",
            "Epoch 7: Loss = 0.21401000249426108\n",
            "Epoch 8: Loss = 0.11071349250001682\n",
            "Epoch 9: Loss = 0.06186388568902338\n",
            "Epoch 10: Loss = 0.04959902284994117\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-977762f7bc7e>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# Test the smoothed classifier on the example image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mtest_smoothed_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;31m# Evaluate the smoothed classifier on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "'''sigma = 0.1\n",
        "n_samples = 100\n",
        "'''\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "'''# Get a batch of test images\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# Pass the first image in the batch to the smoothed classifier test function\n",
        "test_smoothed_classifier(images[0], model, n_samples, sigma)\n",
        "\n",
        "# Load an example image from the test set\n",
        "x, _ = next(iter(test_loader))\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)'''\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenette2', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "a7KOJrD6zq1u",
        "outputId": "f152bc6b-4b23-40e7-aea7-c29d33919b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cba6241d310f>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Define the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m test_dataset = datasets.ImageNet(root='imagenette2', split='val', transform=transforms.Compose([\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCenterCrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m\"You need to download it externally and place it in {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in imagenette2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "srjCCDgnp36x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.7 \n",
        "# Repeat the autoencoder steps with a nonlinear autoencoder and compare the results against PCA and linear encoder.\n",
        "\n",
        "!pip install torch numpy matplotlib sklearn\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "class NonlinearAutoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NonlinearAutoencoder, self).__init__()\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(28 * 28, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 10)\n",
        "        )\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(10, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 28 * 28),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        return x\n",
        "\n",
        "nonlinear_autoencoder = NonlinearAutoencoder()\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nonlinear_autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in trainloader:\n",
        "        img, _ = data\n",
        "        optimizer.zero_grad()\n",
        "        output = nonlinear_autoencoder(img)\n",
        "        loss = criterion(output, img)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n",
        "\n",
        "hidden_representations = []\n",
        "labels = []\n",
        "\n",
        "for data in testloader:\n",
        "    img, label = data\n",
        "    output = autoencoder.encoder(img.view(-1, 28 * 28))\n",
        "    hidden_representations.append(output.detach().numpy())\n",
        "    labels.append(label.numpy())\n",
        "\n",
        "hidden_representations = np.concatenate(hidden_representations, axis=0)\n",
        "labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "tsne = TSNE(n_components=2)\n",
        "hidden_tsne = tsne.fit_transform(hidden_representations)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(10):\n",
        "    plt.scatter(hidden_tsne[labels == i, 0], hidden_tsne[labels == i, 1], label=str(i))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "llpdBuOlp4sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umLjX2l2kSvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/imagenette\n",
        "!pip install torchvision\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/imagenette/imagenette2-160.tgz', 'r:gz') as tar:\n",
        "    tar.extractall('/content/named_folders/imagenet-100')\n"
      ],
      "metadata": {
        "id": "qlMiU66ggzrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "!mkdir imagenet\n",
        "# Define the path to the ImageNet data\n",
        "data_path = './imagenet/'\n",
        "\n",
        "# Define the subset of classes to use\n",
        "classes = ['cat', 'dog', 'bird']\n",
        "\n",
        "# Create a PyTorch dataset using the ImageFolder class\n",
        "dataset = datasets.ImageFolder(root=data_path, \n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                         std=[0.229, 0.224, 0.225])\n",
        "                                ]), \n",
        "                                target_transform=lambda x: classes.index(os.path.basename(os.path.dirname(x))))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset)-500, 500])\n"
      ],
      "metadata": {
        "id": "oMLdFl7-d-iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the ImageNet dataset\n",
        "train_dataset = datasets.ImageNet(root='imagenet', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset.download()\n"
      ],
      "metadata": {
        "id": "RL1scFrwd-qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='path/to/imagenet/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='path/to/imagenet/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "6Q7kAh-CdLaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "c_lFTgLKbEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, noise_std):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = noise_std * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "x = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float().div(255).to(device)\n",
        "\n",
        "\n",
        "n_samples = 100\n",
        "noise_std = 0.1\n",
        "\n",
        "y_smooth = randomized_smoothing(x, model, n_samples, noise_std)\n",
        "pred_label = torch.argmax(y_smooth).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "id": "PxkJUxMYapTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the standard deviation of the Gaussian noise\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the number of samples for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the batch size for evaluation\n",
        "batch_size = 64\n",
        "\n",
        "# Define the device to run the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the ImageNet dataset with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./imagenet/train', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train a ResNet50 model on the dataset\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "for epoch in range(10):\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "testset = torchvision.datasets.ImageFolder(root='./imagenet/val', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "total, correct = 0, 0\n",
        "for i, (inputs, labels) in enumerate(testloader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = smoothed_classifier(inputs, model, n_samples, sigma)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the smoothed classifier on the test set: %.2f%%' % accuracy)\n"
      ],
      "metadata": {
        "id": "cixok1QycKiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}