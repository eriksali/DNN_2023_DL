{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoFtMy+QBxjae0b6/0Wb5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/running_Input_dependent_certification_random_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17ahZXHaocL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcki6APBjvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYA1CxODmxZP",
        "outputId": "1163c19f-fd01-437f-a180-a1c5ad8e7099"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  36.2M      0  0:00:40  0:00:40 --:--:-- 34.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "t_3g8-7IgXJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the model architecture\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = torch.nn.Linear(128 * 16 * 16, 256)\n",
        "        self.fc2 = torch.nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128 * 16 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the random smoothing function\n",
        "def random_smoothing(model, images, n_samples=10, epsilon=0.03):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        smooth_probs = torch.zeros((len(images), 10))\n",
        "        for i in range(n_samples):\n",
        "            smooth_probs += F.softmax(model(images + torch.randn_like(images) * epsilon), dim=1)\n",
        "        smooth_probs /= n_samples\n",
        "    return smooth_probs\n",
        "\n",
        "# Define the evaluation function\n",
        "def evaluate(model, dataloader, n_samples=10, epsilon=0.03):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    total_certified = 0\n",
        "    for images, labels in tqdm(dataloader):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # Calculate the prediction of the model\n",
        "        preds = model(images)\n",
        "        # Calculate the accuracy of the model\n",
        "        total_correct += (preds.argmax(dim=1) == labels).sum().item()\n",
        "        total_samples += len(images)\n",
        "        # Calculate the certified accuracy of the model using random smoothing\n",
        "        smooth_probs = random_smoothing(model, images, n_samples, epsilon)\n",
        "        smoothed_preds = smooth_probs.argmax(dim=1)\n",
        "        certified_correct = ((smoothed_preds == preds.argmax(dim=1)) & (smooth_probs.max(dim=1).values >= 0.9)).sum().item()\n",
        "        total_certified += certified_correct\n",
        "    # Calculate and return the accuracies\n",
        "    accuracy = 100.0 * total_correct / total_samples\n",
        "    certified_accuracy = 100.0 * total_certified / total_samples\n",
        "    return accuracy, certified_accuracy\n",
        "\n",
        "# Define the data transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the training and test data\n",
        "train_data = ImageFolder('imagenette2/train', transform=transform)\n",
        "test_data = ImageFolder('imagenette2/val', transform=transform)\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 8\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Define the dataloaders for training and test data\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# Define the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "import torch.optim as optim\n",
        "# Define the optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the smoothing parameters\n",
        "epsilon = 0.1\n",
        "num_smooth = 50\n",
        "num_epochs = 2\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to train mode\n",
        "    model.train()\n",
        "    \n",
        "    # Train the model on the training data\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Perform random smoothing\n",
        "        smoothed_images = torch.zeros_like(images)\n",
        "        for j in range(num_smooth):\n",
        "            smoothed_images += torch.randn_like(images) * epsilon\n",
        "        smoothed_images = smoothed_images.clamp(0, 1)\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass and compute the loss\n",
        "        outputs = model(smoothed_images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimize the weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    # Set the model to eval mode\n",
        "    model.eval()\n",
        "    \n",
        "    # Evaluate the model on the test data\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Perform random smoothing\n",
        "        smoothed_images = torch.zeros_like(images)\n",
        "        for j in range(num_smooth):\n",
        "            smoothed_images += torch.randn_like(images) * epsilon\n",
        "        smoothed_images = smoothed_images.clamp(0, 1)\n",
        "        \n",
        "        # Forward pass and compute the predictions\n",
        "        outputs = model(smoothed_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # Compute the accuracy\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "    accuracy = 100 * correct / total\n",
        "    print('Epoch [{}/{}], Test Accuracy: {} %'.format(epoch+1, num_epochs, accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STigyX63e49k",
        "outputId": "0f7763d3-3fc1-453f-99e2-f307c9e67ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Load the Imagenette2 dataset\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root='./imagenette2/train',\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root='./imagenette2/val',\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        ")\n",
        "\n",
        "# Define the model architecture\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model and define the loss function and optimizer\n",
        "model = Model()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Train the model for 10 epochs\n",
        "num_epochs = 2\n",
        "batch_size = 16\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Epoch [{}/{}], Test Accuracy: {} %'.format(epoch+1, num_epochs, test_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "OcVu2EP-dN-l",
        "outputId": "bd9522cf-4e07-4ca6-9190-a49ea89c1651"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d1f901533a55>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1024) to match target batch_size (16)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "num_classes = 10\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "'''\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "'''\n",
        "\n",
        "\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Reshape the output tensor\n",
        "            output = output.view(-1, num_classes)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Reshape the output tensor\n",
        "                output = output.view(-1, num_classes)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 2\n",
        "\n",
        "\n",
        "batch_size = 128 # or 128 if you retrain the model with a smaller batch size\n",
        "\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes*num_iterations).to(device)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        if num_iterations == 1:\n",
        "            total_score[:, :] += F.softmax(output, dim=1).repeat(1, num_classes)\n",
        "        else:\n",
        "            total_score[:, i*num_classes:(i+1)*num_classes] = F.softmax(output, dim=1)\n",
        "    \n",
        "    total_score = torch.cat([total_score[:, i*num_classes:(i+1)*num_classes] for i in range(num_iterations)], dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "9Jixfuj6Q7_T",
        "outputId": "21273c96-eb4f-4f92-e938-91f493d8ce19"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-4494aa7d27cf>\u001b[0m in \u001b[0;36m<cell line: 188>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Compute the randomized smoothing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mrandomized_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mrandomized_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcert_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-4494aa7d27cf>\u001b[0m in \u001b[0;36mrandomized_score\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mtotal_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mtotal_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mtotal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (10) must match the existing size (1000) at non-singleton dimension 1.  Target sizes: [128, 10].  Tensor sizes: [128, 1000]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                ##margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=2)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 1\n",
        "\n",
        "\n",
        "batch_size = 128 # or 128 if you retrain the model with a smaller batch size\n",
        "\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "num_classes = 1000\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "'''def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations'''\n",
        "\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes*num_iterations).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score[:, i*num_classes:(i+1)*num_classes] += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "w7eZb35CPihy",
        "outputId": "d7807028-a863-461f-cfed-9c9b307a661d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e101457b8825>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Compute the randomized smoothing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mrandomized_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mrandomized_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcert_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e101457b8825>\u001b[0m in \u001b[0;36mrandomized_score\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mnoisy_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mtotal_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 1\n",
        "\n",
        "\n",
        "##batch_size = 10 # or 128 if you retrain the model with a smaller batch size\n",
        "batch_size = 1\n",
        "##test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "# ...\n",
        "\n",
        "'''[cert_acc = 0.0\n",
        "for c in range(num_classes):\n",
        "    for i in range(len(test_loader.dataset)):\n",
        "        data, target = test_loader.dataset[i]\n",
        "        data, target = data.unsqueeze(0).to(device), target.unsqueeze(0).to(device)\n",
        "        \n",
        "]'''\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "num_classes = 10\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "'''def randomized_score(images, labels):\n",
        "    ##total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    total_score = torch.zeros(images.size(0), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "'''\n",
        "\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(images.size(0), 1000).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score[:, :num_classes] / num_iterations\n",
        "\n",
        "\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "##eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "GOblCPwpKsI4",
        "outputId": "31940e0e-b875-43fc-df12-e57bc9de9d1c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-eebe7e21cecb>\u001b[0m in \u001b[0;36m<cell line: 143>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mcert_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcert_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mcert_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcert_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mcert_radius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mcert_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcert_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mcert_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcert_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcert_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cannot reshape tensor of 0 elements into shape [0, -1] because the unspecified dimension size -1 can be any value and is ambiguous"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "'''# Load the training dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2', transform=transform)\n",
        "##trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)'''\n",
        "\n",
        "'''# Define the neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(7 * 7 * 512, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.pool(F.relu(self.conv6(x)))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.pool(F.relu(self.conv8(x)))\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x'''\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "##model.eval()\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion, batch_size=128):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=128):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=128):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                ##margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=2)[0]\n",
        "\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 1\n",
        "\n",
        "\n",
        "batch_size = 128 # or 128 if you retrain the model with a smaller batch size\n",
        "'''input_data_batch = torch.utils.data.DataLoader(input_data, batch_size=batch_size, shuffle=True)\n",
        "target_data_batch = torch.utils.data.DataLoader(target_data, batch_size=batch_size, shuffle=True)\n",
        "'''\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "'''# Define the neural network model, optimizer, and loss function\n",
        "import torch.optim as optim\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    \n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "'''\n",
        "radius = 0.1\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "num_classes = 10\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "'''# Train the model\n",
        "train(model, device, trainloader, optimizer, criterion)'''\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=1, batch_size=128)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "BmaWNHr4IhmA",
        "outputId": "80bac3b7-b82e-4188-fa3d-38891d290e2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ba0417846846>\u001b[0m in \u001b[0;36m<cell line: 191>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Compute the randomized smoothing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mrandomized_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mrandomized_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mcert_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_predicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ba0417846846>\u001b[0m in \u001b[0;36mrandomized_score\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mnoisy_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mtotal_score\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_score\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (1000) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageNet\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define dataset and data loader\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Define the transformation pipeline for the input images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the test set\n",
        "test_dir = 'imagenette2/val/'\n",
        "test_dataset = ImageFolder(test_dir, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
        "\n",
        "# Load the model\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "'''\n",
        "dataset = ImageNet(root='./imagenette2', split='train', transform=data_transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Train a ResNet50 model on ImageNet with Gaussian data augmentation\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "def train_model(model, optimizer, scheduler, dataloader, epochs=100, sigma=0.1):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Generate Gaussian noise\n",
        "            noise = sigma * torch.randn_like(inputs).to(device)\n",
        "\n",
        "            # Add noise to inputs\n",
        "            inputs_noisy = inputs + noise\n",
        "\n",
        "            # Compute logits\n",
        "            logits = model(inputs_noisy)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute running loss and accuracy\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            predicted = torch.argmax(logits, dim=1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "    # Return the trained model\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, optimizer, scheduler, dataloader, epochs=10, sigma=0.1)'''\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = sigma * torch.randn_like(x).to(device)\n",
        "            logits[i] = model(x + noise)\n",
        "        avg_logits = torch.mean(logits, dim=0)\n",
        "        return avg_logits\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = data_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "n_samples = 100\n",
        "sigma = 0.1\n",
        "\n",
        "logits = smoothed_classifier(img, model, n_samples, sigma)\n",
        "pred_label = torch.argmax(logits).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "oMB9m3ARmSj0",
        "outputId": "b6dad597-ea18-4f32-dd01-1b40d14d6580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5c618ab95541>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./imagenette2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m\"You need to download it externally and place it in {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./imagenette2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YFDbiG5mSnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kD1ZHokmSrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRkzVPwpjvev",
        "outputId": "940e661a-955a-4367-8036-dde7dcab1003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  42.1M      0  0:00:35  0:00:35 --:--:-- 41.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')\n"
      ],
      "metadata": {
        "id": "VLASyAu8kMEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='imagenette2/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "WvQZOk7nkSqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umLjX2l2kSvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/imagenette\n",
        "!pip install torchvision\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/imagenette/imagenette2-160.tgz', 'r:gz') as tar:\n",
        "    tar.extractall('/content/named_folders/imagenet-100')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "qlMiU66ggzrv",
        "outputId": "3d0e5a3c-9982-4895-fe94-1307a39893ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'imagenette' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c96e191eaec1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/imagenette/imagenette2-160.tgz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/named_folders/imagenet-100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1636\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown compression type %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcomptype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"|\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/imagenette/imagenette2-160.tgz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "!mkdir imagenet\n",
        "# Define the path to the ImageNet data\n",
        "data_path = './imagenet/'\n",
        "\n",
        "# Define the subset of classes to use\n",
        "classes = ['cat', 'dog', 'bird']\n",
        "\n",
        "# Create a PyTorch dataset using the ImageFolder class\n",
        "dataset = datasets.ImageFolder(root=data_path, \n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                         std=[0.229, 0.224, 0.225])\n",
        "                                ]), \n",
        "                                target_transform=lambda x: classes.index(os.path.basename(os.path.dirname(x))))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset)-500, 500])\n"
      ],
      "metadata": {
        "id": "oMLdFl7-d-iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the ImageNet dataset\n",
        "train_dataset = datasets.ImageNet(root='imagenet', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset.download()\n"
      ],
      "metadata": {
        "id": "RL1scFrwd-qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='path/to/imagenet/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='path/to/imagenet/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "6Q7kAh-CdLaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "c_lFTgLKbEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, noise_std):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = noise_std * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "x = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float().div(255).to(device)\n",
        "\n",
        "\n",
        "n_samples = 100\n",
        "noise_std = 0.1\n",
        "\n",
        "y_smooth = randomized_smoothing(x, model, n_samples, noise_std)\n",
        "pred_label = torch.argmax(y_smooth).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "id": "PxkJUxMYapTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the standard deviation of the Gaussian noise\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the number of samples for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the batch size for evaluation\n",
        "batch_size = 64\n",
        "\n",
        "# Define the device to run the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the ImageNet dataset with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./imagenet/train', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train a ResNet50 model on the dataset\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "for epoch in range(10):\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "testset = torchvision.datasets.ImageFolder(root='./imagenet/val', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "total, correct = 0, 0\n",
        "for i, (inputs, labels) in enumerate(testloader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = smoothed_classifier(inputs, model, n_samples, sigma)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the smoothed classifier on the test set: %.2f%%' % accuracy)\n"
      ],
      "metadata": {
        "id": "cixok1QycKiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}