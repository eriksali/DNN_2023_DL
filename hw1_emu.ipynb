{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNee1DPQvlVoMtfhI1WTEnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/hw1_emu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n27qRws6pS6J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 hw1_two_lines.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-OktBgEthvy",
        "outputId": "d4357e03-0e51-44e9-e177-bd50413bff97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"hw1_two_lines.py\", line 40\n",
            "    s=session.run(merged)\n",
            "                        ^\n",
            "TabError: inconsistent use of tabs and spaces in indentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the next modules:\n",
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "##########################\n",
        "\n",
        "#load data\n",
        "# x_data = np.load('/content/x_hw.npy')\n",
        "# y_data = np.load('/content/y_hw.npy')\n",
        "\n",
        "x_data = np.linspace(-math.pi, math.pi, 20)\n",
        "y_data = np.sin(x_data)\n",
        "\n",
        "#y_data_ = np.load('/content/y_hw.npy', allow_pickle=True)\n",
        "\n",
        "#create variables\n",
        "A1 = tf.Variable(tf.ones([1]))\n",
        "A2 = tf.Variable(tf.zeros([1]))\n",
        "\n",
        "f1 = tf.Variable(tf.ones([1]))\n",
        "f2 = tf.Variable(tf.ones([1]))\n",
        "\n",
        "#create linear model\n",
        "y = A1*tf.sin(f1*x_data) + A2*tf.sin(f2*x_data) \n",
        "\n",
        "#distance between labels and predicted values\n",
        "loss = tf.reduce_mean(tf.square(y - y_data))\n",
        "\n",
        "#optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
        "#optimizer = tf.train.AdamOptimizer(0.007)\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(0.007)\n",
        "train_step = optimizer.minimize(loss)\n",
        "\n",
        "#init = tf.initialize_all_variables()\n",
        "#this initializes all variables\n",
        "# session = tf.InteractiveSession()\n",
        "session = tf.compat.v1.InteractiveSession()\n",
        "tf.compat.v1.global_variables_initializer().run()\n",
        "\n",
        "#saver = tf.train.Saver() #saves the states of the network\n",
        "N= 10000\n",
        "for k in range(N):\n",
        "  session.run(train_step)\n",
        "  if k > 800 and k < 1000:\n",
        "    print(\"k =\",k, \"A1 =\", session.run(A1[0]), \"A2 =\", session.run(A2[0]), \"f1 =\", session.run(f1[0]), \"f2 =\", session.run(f2[0]), \"loss =\",session.run(loss) )\n",
        "\n",
        "\n",
        "AA1, AA2, ff1, ff2 = session.run([A1,A2,f1,f2])\n",
        "AA1 = AA1[0]\n",
        "AA2 = AA2[0]\n",
        "ff1 = ff1[0]\n",
        "ff2 = ff2[0]\n",
        "print(\"AA1 = \" + str(AA1)) \n",
        "print(\"ff1 = \" + str(ff1)) \n",
        "print(\"AA2 = \" + str(AA2))\n",
        "print(\"ff2 = \" + str(ff2)) \n",
        "print(\"y = \" + str(AA1) + \"*sin(\" + str(ff1) + \")\" + \" + \" + str(AA2) +  \"*sin(\" + str(ff2) + \")\")\n",
        "value = AA1*np.sin(ff1*0.6*np.pi) + AA2*np.sin(ff2*0.6*np.pi)\n",
        "print(\"The value at 0.6*pi = \" + str(value)) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_9mSoTHuCot",
        "outputId": "99e5776e-95e0-4954-8197-a5145dff7ba0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 801 A1 = 0.99966395 A2 = 0.00033929604 f1 = 0.99997 f2 = 1.0871129 loss = 1.7243203e-12\n",
            "k = 802 A1 = 0.99966407 A2 = 0.00033923937 f1 = 0.9999699 f2 = 1.0871127 loss = 1.7841938e-12\n",
            "k = 803 A1 = 0.999664 A2 = 0.0003390962 f1 = 0.99997 f2 = 1.0871125 loss = 1.7363801e-12\n",
            "k = 804 A1 = 0.9996642 A2 = 0.0003391229 f1 = 0.99996996 f2 = 1.0871124 loss = 1.6701047e-12\n",
            "k = 805 A1 = 0.99966425 A2 = 0.00033905148 f1 = 0.99997 f2 = 1.0871123 loss = 1.728935e-12\n",
            "k = 806 A1 = 0.99966425 A2 = 0.000338905 f1 = 0.99996996 f2 = 1.0871122 loss = 1.6652863e-12\n",
            "k = 807 A1 = 0.9996643 A2 = 0.00033885532 f1 = 0.99997 f2 = 1.0871121 loss = 1.7220802e-12\n",
            "k = 808 A1 = 0.9996645 A2 = 0.00033890444 f1 = 0.99997 f2 = 1.087112 loss = 1.7260883e-12\n",
            "k = 809 A1 = 0.9996645 A2 = 0.0003387711 f1 = 0.99996996 f2 = 1.0871118 loss = 1.6955323e-12\n",
            "k = 810 A1 = 0.9996644 A2 = 0.0003386221 f1 = 0.9999701 f2 = 1.0871117 loss = 1.6881949e-12\n",
            "k = 811 A1 = 0.99966466 A2 = 0.0003387096 f1 = 0.99996996 f2 = 1.0871115 loss = 1.6763899e-12\n",
            "k = 812 A1 = 0.99966466 A2 = 0.000338599 f1 = 0.9999701 f2 = 1.0871114 loss = 1.6677472e-12\n",
            "k = 813 A1 = 0.99966466 A2 = 0.0003384621 f1 = 0.9999701 f2 = 1.0871112 loss = 1.6634917e-12\n",
            "k = 814 A1 = 0.9996648 A2 = 0.00033845086 f1 = 0.99996996 f2 = 1.087111 loss = 1.6903423e-12\n",
            "k = 815 A1 = 0.99966484 A2 = 0.00033841084 f1 = 0.9999701 f2 = 1.0871109 loss = 1.6687531e-12\n",
            "k = 816 A1 = 0.9996649 A2 = 0.0003383343 f1 = 0.9999701 f2 = 1.0871108 loss = 1.6575425e-12\n",
            "k = 817 A1 = 0.99966496 A2 = 0.0003382456 f1 = 0.99997 f2 = 1.0871106 loss = 1.7497736e-12\n",
            "k = 818 A1 = 0.999665 A2 = 0.00033817062 f1 = 0.99997 f2 = 1.0871105 loss = 1.7026016e-12\n",
            "k = 819 A1 = 0.99966514 A2 = 0.0003381504 f1 = 0.9999701 f2 = 1.0871104 loss = 1.635358e-12\n",
            "k = 820 A1 = 0.99966514 A2 = 0.00033804085 f1 = 0.99997014 f2 = 1.0871103 loss = 1.6477288e-12\n",
            "k = 821 A1 = 0.9996652 A2 = 0.0003379619 f1 = 0.99996996 f2 = 1.08711 loss = 1.6943955e-12\n",
            "k = 822 A1 = 0.99966526 A2 = 0.00033794888 f1 = 0.99997014 f2 = 1.0871099 loss = 1.6596114e-12\n",
            "k = 823 A1 = 0.9996654 A2 = 0.00033792248 f1 = 0.99997014 f2 = 1.0871098 loss = 1.6707163e-12\n",
            "k = 824 A1 = 0.9996654 A2 = 0.0003377633 f1 = 0.99996996 f2 = 1.0871096 loss = 1.7077245e-12\n",
            "k = 825 A1 = 0.99966544 A2 = 0.00033771008 f1 = 0.9999702 f2 = 1.0871094 loss = 1.7521328e-12\n",
            "k = 826 A1 = 0.9996656 A2 = 0.00033773243 f1 = 0.99997014 f2 = 1.0871093 loss = 1.648489e-12\n",
            "k = 827 A1 = 0.99966556 A2 = 0.0003375273 f1 = 0.99997 f2 = 1.0871091 loss = 1.7483877e-12\n",
            "k = 828 A1 = 0.9996657 A2 = 0.00033750758 f1 = 0.9999701 f2 = 1.087109 loss = 1.6382043e-12\n",
            "k = 829 A1 = 0.9996658 A2 = 0.0003375223 f1 = 0.99997026 f2 = 1.0871089 loss = 1.7468929e-12\n",
            "k = 830 A1 = 0.9996659 A2 = 0.00033745612 f1 = 0.9999701 f2 = 1.0871086 loss = 1.6578703e-12\n",
            "k = 831 A1 = 0.99966586 A2 = 0.00033724293 f1 = 0.9999701 f2 = 1.0871085 loss = 1.677667e-12\n",
            "k = 832 A1 = 0.9996659 A2 = 0.0003371765 f1 = 0.99997026 f2 = 1.0871084 loss = 1.7682175e-12\n",
            "k = 833 A1 = 0.99966615 A2 = 0.0003372783 f1 = 0.9999701 f2 = 1.0871081 loss = 1.6692056e-12\n",
            "k = 834 A1 = 0.9996661 A2 = 0.00033710906 f1 = 0.9999702 f2 = 1.087108 loss = 1.7563355e-12\n",
            "k = 835 A1 = 0.9996661 A2 = 0.0003369389 f1 = 0.9999702 f2 = 1.0871079 loss = 1.7669948e-12\n",
            "k = 836 A1 = 0.9996663 A2 = 0.0003369812 f1 = 0.9999701 f2 = 1.0871077 loss = 1.654511e-12\n",
            "k = 837 A1 = 0.99966633 A2 = 0.0003369508 f1 = 0.9999702 f2 = 1.0871075 loss = 1.7637405e-12\n",
            "k = 838 A1 = 0.99966633 A2 = 0.00033680958 f1 = 0.99997026 f2 = 1.0871074 loss = 1.7514327e-12\n",
            "k = 839 A1 = 0.99966645 A2 = 0.00033677937 f1 = 0.99997014 f2 = 1.0871072 loss = 1.6199544e-12\n",
            "k = 840 A1 = 0.9996665 A2 = 0.00033668906 f1 = 0.99997014 f2 = 1.0871071 loss = 1.618294e-12\n",
            "k = 841 A1 = 0.9996665 A2 = 0.00033658659 f1 = 0.99997026 f2 = 1.087107 loss = 1.7052942e-12\n",
            "k = 842 A1 = 0.9996667 A2 = 0.00033663772 f1 = 0.9999702 f2 = 1.0871068 loss = 1.7262384e-12\n",
            "k = 843 A1 = 0.9996667 A2 = 0.00033650556 f1 = 0.9999702 f2 = 1.0871067 loss = 1.7190216e-12\n",
            "k = 844 A1 = 0.9996667 A2 = 0.0003363868 f1 = 0.99997026 f2 = 1.0871066 loss = 1.7289458e-12\n",
            "k = 845 A1 = 0.9996669 A2 = 0.00033646714 f1 = 0.9999702 f2 = 1.0871063 loss = 1.7516582e-12\n",
            "k = 846 A1 = 0.99966687 A2 = 0.00033627663 f1 = 0.99997026 f2 = 1.0871062 loss = 1.7126535e-12\n",
            "k = 847 A1 = 0.9996669 A2 = 0.00033618248 f1 = 0.99997026 f2 = 1.0871061 loss = 1.7140289e-12\n",
            "k = 848 A1 = 0.9996671 A2 = 0.00033619843 f1 = 0.9999702 f2 = 1.0871059 loss = 1.7302429e-12\n",
            "k = 849 A1 = 0.9996671 A2 = 0.0003360782 f1 = 0.99997026 f2 = 1.0871058 loss = 1.6951026e-12\n",
            "k = 850 A1 = 0.99966717 A2 = 0.00033601202 f1 = 0.9999703 f2 = 1.0871056 loss = 1.6234097e-12\n",
            "k = 851 A1 = 0.9996673 A2 = 0.00033598108 f1 = 0.99997026 f2 = 1.0871054 loss = 1.694357e-12\n",
            "k = 852 A1 = 0.9996673 A2 = 0.000335853 f1 = 0.9999702 f2 = 1.0871053 loss = 1.7175612e-12\n",
            "k = 853 A1 = 0.99966735 A2 = 0.00033579147 f1 = 0.9999704 f2 = 1.0871052 loss = 1.6507562e-12\n",
            "k = 854 A1 = 0.9996675 A2 = 0.0003358066 f1 = 0.9999702 f2 = 1.0871049 loss = 1.7425922e-12\n",
            "k = 855 A1 = 0.99966747 A2 = 0.00033562092 f1 = 0.9999703 f2 = 1.0871048 loss = 1.6221798e-12\n",
            "k = 856 A1 = 0.9996675 A2 = 0.00033557197 f1 = 0.9999703 f2 = 1.0871047 loss = 1.6182444e-12\n",
            "k = 857 A1 = 0.9996677 A2 = 0.00033562668 f1 = 0.99997026 f2 = 1.0871044 loss = 1.7018473e-12\n",
            "k = 858 A1 = 0.9996677 A2 = 0.00033550535 f1 = 0.9999704 f2 = 1.0871043 loss = 1.6250789e-12\n",
            "k = 859 A1 = 0.99966776 A2 = 0.00033537566 f1 = 0.99997026 f2 = 1.0871041 loss = 1.7198881e-12\n",
            "k = 860 A1 = 0.9996679 A2 = 0.0003353561 f1 = 0.99997026 f2 = 1.087104 loss = 1.7200939e-12\n",
            "k = 861 A1 = 0.9996679 A2 = 0.00033528853 f1 = 0.99997044 f2 = 1.0871038 loss = 1.7163649e-12\n",
            "k = 862 A1 = 0.999668 A2 = 0.00033524254 f1 = 0.9999704 f2 = 1.0871036 loss = 1.5904457e-12\n",
            "k = 863 A1 = 0.9996681 A2 = 0.00033515767 f1 = 0.9999702 f2 = 1.0871034 loss = 1.7737926e-12\n",
            "k = 864 A1 = 0.999668 A2 = 0.00033493814 f1 = 0.99997044 f2 = 1.0871032 loss = 1.677793e-12\n",
            "k = 865 A1 = 0.99966824 A2 = 0.00033503343 f1 = 0.99997044 f2 = 1.0871031 loss = 1.7167289e-12\n",
            "k = 866 A1 = 0.99966836 A2 = 0.0003349812 f1 = 0.9999703 f2 = 1.0871029 loss = 1.6511292e-12\n",
            "k = 867 A1 = 0.99966824 A2 = 0.00033470264 f1 = 0.9999704 f2 = 1.0871028 loss = 1.6434902e-12\n",
            "k = 868 A1 = 0.9996685 A2 = 0.00033478063 f1 = 0.9999703 f2 = 1.0871025 loss = 1.643757e-12\n",
            "k = 869 A1 = 0.99966854 A2 = 0.00033474716 f1 = 0.99997044 f2 = 1.0871024 loss = 1.6886596e-12\n",
            "k = 870 A1 = 0.9996685 A2 = 0.000334565 f1 = 0.99997044 f2 = 1.0871023 loss = 1.68801e-12\n",
            "k = 871 A1 = 0.9996686 A2 = 0.00033455144 f1 = 0.9999704 f2 = 1.087102 loss = 1.5928728e-12\n",
            "k = 872 A1 = 0.9996688 A2 = 0.0003345958 f1 = 0.9999703 f2 = 1.0871018 loss = 1.6587961e-12\n",
            "k = 873 A1 = 0.99966866 A2 = 0.0003343793 f1 = 0.9999705 f2 = 1.0871017 loss = 1.6933002e-12\n",
            "k = 874 A1 = 0.9996688 A2 = 0.00033436777 f1 = 0.99997044 f2 = 1.0871015 loss = 1.668541e-12\n",
            "k = 875 A1 = 0.99966896 A2 = 0.00033436518 f1 = 0.9999704 f2 = 1.0871012 loss = 1.6205873e-12\n",
            "k = 876 A1 = 0.9996689 A2 = 0.0003341773 f1 = 0.9999704 f2 = 1.0871011 loss = 1.5992508e-12\n",
            "k = 877 A1 = 0.999669 A2 = 0.0003341588 f1 = 0.99997044 f2 = 1.087101 loss = 1.6682882e-12\n",
            "k = 878 A1 = 0.9996691 A2 = 0.00033409699 f1 = 0.99997056 f2 = 1.0871009 loss = 1.6994646e-12\n",
            "k = 879 A1 = 0.99966925 A2 = 0.00033405898 f1 = 0.9999703 f2 = 1.0871006 loss = 1.681475e-12\n",
            "k = 880 A1 = 0.99966913 A2 = 0.0003338463 f1 = 0.99997044 f2 = 1.0871005 loss = 1.6705228e-12\n",
            "k = 881 A1 = 0.99966925 A2 = 0.00033385184 f1 = 0.9999706 f2 = 1.0871004 loss = 1.696554e-12\n",
            "k = 882 A1 = 0.9996695 A2 = 0.00033391596 f1 = 0.99997026 f2 = 1.0871001 loss = 1.8128393e-12\n",
            "k = 883 A1 = 0.9996693 A2 = 0.0003336497 f1 = 0.99997056 f2 = 1.0871 loss = 1.7553088e-12\n",
            "k = 884 A1 = 0.9996695 A2 = 0.00033370385 f1 = 0.9999705 f2 = 1.0870998 loss = 1.6475047e-12\n",
            "k = 885 A1 = 0.9996697 A2 = 0.00033370493 f1 = 0.9999704 f2 = 1.0870996 loss = 1.6253079e-12\n",
            "k = 886 A1 = 0.9996695 A2 = 0.0003334465 f1 = 0.99997056 f2 = 1.0870994 loss = 1.7258969e-12\n",
            "k = 887 A1 = 0.99966973 A2 = 0.0003335159 f1 = 0.99997044 f2 = 1.0870992 loss = 1.6854157e-12\n",
            "k = 888 A1 = 0.9996698 A2 = 0.00033347044 f1 = 0.99997056 f2 = 1.0870991 loss = 1.7214141e-12\n",
            "k = 889 A1 = 0.9996698 A2 = 0.00033332861 f1 = 0.9999705 f2 = 1.0870988 loss = 1.6464111e-12\n",
            "k = 890 A1 = 0.99966985 A2 = 0.00033325978 f1 = 0.99997044 f2 = 1.0870986 loss = 1.6591537e-12\n",
            "k = 891 A1 = 0.9996699 A2 = 0.00033323432 f1 = 0.9999707 f2 = 1.0870985 loss = 1.7414944e-12\n",
            "k = 892 A1 = 0.9996701 A2 = 0.00033323586 f1 = 0.9999704 f2 = 1.0870982 loss = 1.6600457e-12\n",
            "k = 893 A1 = 0.99967 A2 = 0.0003330536 f1 = 0.99997044 f2 = 1.0870981 loss = 1.6991221e-12\n",
            "k = 894 A1 = 0.99967 A2 = 0.00033297428 f1 = 0.9999708 f2 = 1.087098 loss = 1.8738557e-12\n",
            "k = 895 A1 = 0.99967045 A2 = 0.00033315393 f1 = 0.9999703 f2 = 1.0870978 loss = 1.8276383e-12\n",
            "k = 896 A1 = 0.99967015 A2 = 0.00033273431 f1 = 0.9999706 f2 = 1.0870976 loss = 1.6484276e-12\n",
            "k = 897 A1 = 0.99967027 A2 = 0.000332692 f1 = 0.99997056 f2 = 1.0870974 loss = 1.6792462e-12\n",
            "k = 898 A1 = 0.9996707 A2 = 0.00033294148 f1 = 0.99997044 f2 = 1.0870972 loss = 1.8258342e-12\n",
            "k = 899 A1 = 0.9996704 A2 = 0.00033255026 f1 = 0.99997085 f2 = 1.087097 loss = 1.9077261e-12\n",
            "k = 900 A1 = 0.99967057 A2 = 0.00033249622 f1 = 0.9999703 f2 = 1.0870968 loss = 1.7336899e-12\n",
            "k = 901 A1 = 0.9996707 A2 = 0.00033253556 f1 = 0.99997056 f2 = 1.0870967 loss = 1.696042e-12\n",
            "k = 902 A1 = 0.99967074 A2 = 0.0003325136 f1 = 0.9999708 f2 = 1.0870966 loss = 1.7625606e-12\n",
            "k = 903 A1 = 0.99967086 A2 = 0.00033238655 f1 = 0.9999704 f2 = 1.0870963 loss = 1.6747943e-12\n",
            "k = 904 A1 = 0.99967074 A2 = 0.00033217677 f1 = 0.99997056 f2 = 1.0870962 loss = 1.6897416e-12\n",
            "k = 905 A1 = 0.999671 A2 = 0.0003323135 f1 = 0.9999708 f2 = 1.0870961 loss = 1.7511632e-12\n",
            "k = 906 A1 = 0.99967116 A2 = 0.00033227546 f1 = 0.99997044 f2 = 1.0870959 loss = 1.7955183e-12\n",
            "k = 907 A1 = 0.9996708 A2 = 0.00033181463 f1 = 0.99997073 f2 = 1.0870957 loss = 1.9024554e-12\n",
            "k = 908 A1 = 0.9996713 A2 = 0.0003321186 f1 = 0.99997056 f2 = 1.0870955 loss = 1.7130759e-12\n",
            "k = 909 A1 = 0.9996714 A2 = 0.00033208623 f1 = 0.9999706 f2 = 1.0870954 loss = 1.624505e-12\n",
            "k = 910 A1 = 0.99967104 A2 = 0.0003315713 f1 = 0.9999707 f2 = 1.0870953 loss = 1.779342e-12\n",
            "k = 911 A1 = 0.99967146 A2 = 0.00033180285 f1 = 0.9999705 f2 = 1.087095 loss = 1.7171086e-12\n",
            "k = 912 A1 = 0.9996716 A2 = 0.00033185288 f1 = 0.9999708 f2 = 1.0870949 loss = 1.7256211e-12\n",
            "k = 913 A1 = 0.99967146 A2 = 0.00033155474 f1 = 0.9999707 f2 = 1.0870947 loss = 1.6382392e-12\n",
            "k = 914 A1 = 0.9996716 A2 = 0.00033147907 f1 = 0.99997044 f2 = 1.0870944 loss = 1.7891099e-12\n",
            "k = 915 A1 = 0.99967164 A2 = 0.00033150197 f1 = 0.9999709 f2 = 1.0870943 loss = 1.686307e-12\n",
            "k = 916 A1 = 0.9996718 A2 = 0.0003315088 f1 = 0.9999707 f2 = 1.0870941 loss = 1.6062313e-12\n",
            "k = 917 A1 = 0.99967176 A2 = 0.00033128166 f1 = 0.99997044 f2 = 1.0870938 loss = 1.8063535e-12\n",
            "k = 918 A1 = 0.9996717 A2 = 0.0003311889 f1 = 0.999971 f2 = 1.0870937 loss = 1.7972717e-12\n",
            "k = 919 A1 = 0.9996722 A2 = 0.00033146626 f1 = 0.9999705 f2 = 1.0870935 loss = 1.8848159e-12\n",
            "k = 920 A1 = 0.9996719 A2 = 0.00033104088 f1 = 0.99997073 f2 = 1.0870934 loss = 1.7260294e-12\n",
            "k = 921 A1 = 0.9996719 A2 = 0.00033094682 f1 = 0.99997085 f2 = 1.0870932 loss = 1.7509347e-12\n",
            "k = 922 A1 = 0.9996724 A2 = 0.00033129752 f1 = 0.99997044 f2 = 1.087093 loss = 2.069565e-12\n",
            "k = 923 A1 = 0.999672 A2 = 0.00033082662 f1 = 0.99997103 f2 = 1.0870929 loss = 1.9595892e-12\n",
            "k = 924 A1 = 0.9996723 A2 = 0.0003308788 f1 = 0.9999706 f2 = 1.0870926 loss = 1.6035032e-12\n",
            "k = 925 A1 = 0.9996724 A2 = 0.00033085953 f1 = 0.9999705 f2 = 1.0870924 loss = 1.799751e-12\n",
            "k = 926 A1 = 0.9996722 A2 = 0.00033062042 f1 = 0.9999711 f2 = 1.0870923 loss = 1.9612723e-12\n",
            "k = 927 A1 = 0.99967265 A2 = 0.00033085328 f1 = 0.99997056 f2 = 1.087092 loss = 1.8066787e-12\n",
            "k = 928 A1 = 0.99967253 A2 = 0.00033057824 f1 = 0.9999706 f2 = 1.0870919 loss = 1.6262812e-12\n",
            "k = 929 A1 = 0.99967235 A2 = 0.00033035557 f1 = 0.999971 f2 = 1.0870918 loss = 1.7897994e-12\n",
            "k = 930 A1 = 0.99967295 A2 = 0.0003307384 f1 = 0.99997056 f2 = 1.0870916 loss = 1.9014811e-12\n",
            "k = 931 A1 = 0.9996727 A2 = 0.0003303798 f1 = 0.9999708 f2 = 1.0870914 loss = 1.6379915e-12\n",
            "k = 932 A1 = 0.9996726 A2 = 0.00033012242 f1 = 0.99997085 f2 = 1.0870913 loss = 1.727391e-12\n",
            "k = 933 A1 = 0.9996731 A2 = 0.0003304566 f1 = 0.9999706 f2 = 1.0870911 loss = 1.7611136e-12\n",
            "k = 934 A1 = 0.9996729 A2 = 0.0003300969 f1 = 0.9999709 f2 = 1.087091 loss = 1.5974094e-12\n",
            "k = 935 A1 = 0.99967295 A2 = 0.000329962 f1 = 0.99997073 f2 = 1.0870907 loss = 1.6924268e-12\n",
            "k = 936 A1 = 0.99967325 A2 = 0.0003301183 f1 = 0.99997073 f2 = 1.0870905 loss = 1.7149684e-12\n",
            "k = 937 A1 = 0.9996732 A2 = 0.00032994652 f1 = 0.999971 f2 = 1.0870904 loss = 1.5854002e-12\n",
            "k = 938 A1 = 0.99967325 A2 = 0.00032979212 f1 = 0.9999707 f2 = 1.0870901 loss = 1.6272728e-12\n",
            "k = 939 A1 = 0.9996733 A2 = 0.00032974704 f1 = 0.99997073 f2 = 1.08709 loss = 1.7087214e-12\n",
            "k = 940 A1 = 0.9996734 A2 = 0.0003297989 f1 = 0.99997103 f2 = 1.0870899 loss = 1.7586859e-12\n",
            "k = 941 A1 = 0.99967355 A2 = 0.00032973572 f1 = 0.99997073 f2 = 1.0870897 loss = 1.7067188e-12\n",
            "k = 942 A1 = 0.9996734 A2 = 0.0003294642 f1 = 0.99997073 f2 = 1.0870895 loss = 1.7314446e-12\n",
            "k = 943 A1 = 0.9996736 A2 = 0.00032952733 f1 = 0.99997103 f2 = 1.0870894 loss = 1.7331376e-12\n",
            "k = 944 A1 = 0.9996739 A2 = 0.0003296264 f1 = 0.99997073 f2 = 1.0870892 loss = 1.7929349e-12\n",
            "k = 945 A1 = 0.99967355 A2 = 0.00032917134 f1 = 0.9999709 f2 = 1.0870891 loss = 1.6394823e-12\n",
            "k = 946 A1 = 0.99967384 A2 = 0.00032928033 f1 = 0.9999708 f2 = 1.0870888 loss = 1.6140304e-12\n",
            "k = 947 A1 = 0.9996741 A2 = 0.0003293953 f1 = 0.9999709 f2 = 1.0870887 loss = 1.630078e-12\n",
            "k = 948 A1 = 0.99967384 A2 = 0.0003290115 f1 = 0.9999709 f2 = 1.0870886 loss = 1.5924585e-12\n",
            "k = 949 A1 = 0.999674 A2 = 0.00032902297 f1 = 0.99997073 f2 = 1.0870883 loss = 1.7249226e-12\n",
            "k = 950 A1 = 0.9996742 A2 = 0.00032912483 f1 = 0.99997103 f2 = 1.0870882 loss = 1.701557e-12\n",
            "k = 951 A1 = 0.9996742 A2 = 0.00032896645 f1 = 0.9999709 f2 = 1.087088 loss = 1.5481484e-12\n",
            "k = 952 A1 = 0.99967414 A2 = 0.000328737 f1 = 0.9999708 f2 = 1.0870878 loss = 1.6703916e-12\n",
            "k = 953 A1 = 0.9996744 A2 = 0.00032885667 f1 = 0.9999709 f2 = 1.0870876 loss = 1.5630931e-12\n",
            "k = 954 A1 = 0.99967444 A2 = 0.00032878775 f1 = 0.99997103 f2 = 1.0870875 loss = 1.6970531e-12\n",
            "k = 955 A1 = 0.99967444 A2 = 0.00032858696 f1 = 0.9999708 f2 = 1.0870873 loss = 1.6619512e-12\n",
            "k = 956 A1 = 0.9996745 A2 = 0.00032851743 f1 = 0.9999709 f2 = 1.0870872 loss = 1.5509885e-12\n",
            "k = 957 A1 = 0.9996747 A2 = 0.00032855742 f1 = 0.99997103 f2 = 1.087087 loss = 1.679304e-12\n",
            "k = 958 A1 = 0.99967474 A2 = 0.00032843728 f1 = 0.9999709 f2 = 1.0870868 loss = 1.5430376e-12\n",
            "k = 959 A1 = 0.9996747 A2 = 0.00032823606 f1 = 0.9999709 f2 = 1.0870866 loss = 1.5711067e-12\n",
            "k = 960 A1 = 0.99967486 A2 = 0.00032830358 f1 = 0.999971 f2 = 1.0870864 loss = 1.5354153e-12\n",
            "k = 961 A1 = 0.99967504 A2 = 0.00032829845 f1 = 0.9999709 f2 = 1.0870862 loss = 1.54895e-12\n",
            "k = 962 A1 = 0.99967486 A2 = 0.00032797435 f1 = 0.99997103 f2 = 1.0870861 loss = 1.7030839e-12\n",
            "k = 963 A1 = 0.9996751 A2 = 0.00032806912 f1 = 0.9999709 f2 = 1.0870858 loss = 1.5476489e-12\n",
            "k = 964 A1 = 0.9996752 A2 = 0.00032806603 f1 = 0.999971 f2 = 1.0870857 loss = 1.510228e-12\n",
            "k = 965 A1 = 0.99967515 A2 = 0.0003278404 f1 = 0.99997103 f2 = 1.0870856 loss = 1.6513754e-12\n",
            "k = 966 A1 = 0.9996753 A2 = 0.000327821 f1 = 0.999971 f2 = 1.0870854 loss = 1.5210232e-12\n",
            "k = 967 A1 = 0.99967545 A2 = 0.00032782805 f1 = 0.9999709 f2 = 1.0870851 loss = 1.5820407e-12\n",
            "k = 968 A1 = 0.9996753 A2 = 0.00032756536 f1 = 0.9999711 f2 = 1.087085 loss = 1.6205113e-12\n",
            "k = 969 A1 = 0.9996755 A2 = 0.00032765715 f1 = 0.999971 f2 = 1.0870848 loss = 1.5331705e-12\n",
            "k = 970 A1 = 0.99967563 A2 = 0.00032764877 f1 = 0.9999709 f2 = 1.0870845 loss = 1.5835921e-12\n",
            "k = 971 A1 = 0.99967545 A2 = 0.00032739568 f1 = 0.9999712 f2 = 1.0870844 loss = 1.7529343e-12\n",
            "k = 972 A1 = 0.9996758 A2 = 0.00032752025 f1 = 0.99997073 f2 = 1.0870842 loss = 1.9092542e-12\n",
            "k = 973 A1 = 0.9996757 A2 = 0.0003273279 f1 = 0.9999712 f2 = 1.087084 loss = 1.6733002e-12\n",
            "k = 974 A1 = 0.9996758 A2 = 0.00032727802 f1 = 0.99997103 f2 = 1.0870838 loss = 1.6267705e-12\n",
            "k = 975 A1 = 0.9996759 A2 = 0.00032725715 f1 = 0.9999709 f2 = 1.0870836 loss = 1.5860979e-12\n",
            "k = 976 A1 = 0.99967587 A2 = 0.00032713416 f1 = 0.9999712 f2 = 1.0870835 loss = 1.636661e-12\n",
            "k = 977 A1 = 0.9996761 A2 = 0.00032718226 f1 = 0.9999709 f2 = 1.0870832 loss = 1.6072442e-12\n",
            "k = 978 A1 = 0.999676 A2 = 0.0003269412 f1 = 0.9999711 f2 = 1.0870831 loss = 1.5894861e-12\n",
            "k = 979 A1 = 0.9996761 A2 = 0.00032695662 f1 = 0.99997115 f2 = 1.087083 loss = 1.6056708e-12\n",
            "k = 980 A1 = 0.99967635 A2 = 0.00032699376 f1 = 0.9999709 f2 = 1.0870827 loss = 1.6031326e-12\n",
            "k = 981 A1 = 0.9996761 A2 = 0.00032667993 f1 = 0.9999712 f2 = 1.0870826 loss = 1.6947763e-12\n",
            "k = 982 A1 = 0.99967647 A2 = 0.00032682662 f1 = 0.999971 f2 = 1.0870824 loss = 1.5470646e-12\n",
            "k = 983 A1 = 0.99967647 A2 = 0.0003266711 f1 = 0.99997103 f2 = 1.0870823 loss = 1.6444213e-12\n",
            "k = 984 A1 = 0.99967635 A2 = 0.00032647804 f1 = 0.99997133 f2 = 1.0870821 loss = 1.8044327e-12\n",
            "k = 985 A1 = 0.9996768 A2 = 0.00032674585 f1 = 0.99997085 f2 = 1.0870819 loss = 1.873579e-12\n",
            "k = 986 A1 = 0.99967647 A2 = 0.00032630196 f1 = 0.99997133 f2 = 1.0870818 loss = 1.797957e-12\n",
            "k = 987 A1 = 0.99967676 A2 = 0.0003263892 f1 = 0.99997103 f2 = 1.0870816 loss = 1.6507462e-12\n",
            "k = 988 A1 = 0.9996769 A2 = 0.00032637265 f1 = 0.9999711 f2 = 1.0870814 loss = 1.5707559e-12\n",
            "k = 989 A1 = 0.9996767 A2 = 0.00032606962 f1 = 0.99997133 f2 = 1.0870813 loss = 1.8114128e-12\n",
            "k = 990 A1 = 0.9996771 A2 = 0.0003262702 f1 = 0.9999709 f2 = 1.0870811 loss = 1.7141228e-12\n",
            "k = 991 A1 = 0.99967694 A2 = 0.0003259857 f1 = 0.9999713 f2 = 1.087081 loss = 1.6767719e-12\n",
            "k = 992 A1 = 0.99967706 A2 = 0.00032593647 f1 = 0.9999712 f2 = 1.0870807 loss = 1.5638261e-12\n",
            "k = 993 A1 = 0.99967736 A2 = 0.00032602643 f1 = 0.9999709 f2 = 1.0870805 loss = 1.7357707e-12\n",
            "k = 994 A1 = 0.999677 A2 = 0.00032565088 f1 = 0.99997145 f2 = 1.0870804 loss = 1.8427135e-12\n",
            "k = 995 A1 = 0.99967754 A2 = 0.00032593252 f1 = 0.99997103 f2 = 1.0870801 loss = 1.7442176e-12\n",
            "k = 996 A1 = 0.9996774 A2 = 0.0003256795 f1 = 0.9999712 f2 = 1.08708 loss = 1.5402231e-12\n",
            "k = 997 A1 = 0.9996773 A2 = 0.00032542535 f1 = 0.9999712 f2 = 1.0870798 loss = 1.6351749e-12\n",
            "k = 998 A1 = 0.9996778 A2 = 0.0003256965 f1 = 0.999971 f2 = 1.0870795 loss = 1.685448e-12\n",
            "k = 999 A1 = 0.99967754 A2 = 0.00032542288 f1 = 0.99997145 f2 = 1.0870794 loss = 1.7044137e-12\n",
            "AA1 = 1.0000001\n",
            "ff1 = 1.0000001\n",
            "AA2 = 6.680201e-07\n",
            "ff2 = 1.2976767\n",
            "y = 1.0000001*sin(1.0000001) + 6.680201e-07*sin(1.2976767)\n",
            "The value at 0.6*pi = 0.9510569882945544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "T = np.array([[3], [4]])\n",
        "print(T)\n",
        "T.shape\n",
        "T[1, 0]\n",
        "T[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "431UtTlTpX0B",
        "outputId": "766560ff-cd61-4195-b2b3-43a920a143de"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3]\n",
            " [4]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9BP69JsqUXC",
        "outputId": "4bd3a68a-2941-490a-9a75-d0c99939e677"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T[0, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rycSRcGhp9dZ",
        "outputId": "b4623feb-b852-4ea8-faac-159efbc565d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T[1, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8I8efMHp5jZ",
        "outputId": "e21839cb-fe7d-4c3b-8006-f9a1355fce7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}