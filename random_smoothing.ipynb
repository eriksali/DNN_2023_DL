{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpcfJ9XfpTspUkLEfeNNpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/random_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17ahZXHaocL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PT2nkpg9p2y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kcki6APBjvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRkzVPwpjvev",
        "outputId": "940e661a-955a-4367-8036-dde7dcab1003"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  42.1M      0  0:00:35  0:00:35 --:--:-- 41.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')\n"
      ],
      "metadata": {
        "id": "VLASyAu8kMEt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='imagenette2/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "WvQZOk7nkSqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "srjCCDgnp36x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.7 \n",
        "# Repeat the autoencoder steps with a nonlinear autoencoder and compare the results against PCA and linear encoder.\n",
        "\n",
        "!pip install torch numpy matplotlib sklearn\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "class NonlinearAutoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NonlinearAutoencoder, self).__init__()\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(28 * 28, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 10)\n",
        "        )\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(10, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 28 * 28),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        return x\n",
        "\n",
        "nonlinear_autoencoder = NonlinearAutoencoder()\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nonlinear_autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in trainloader:\n",
        "        img, _ = data\n",
        "        optimizer.zero_grad()\n",
        "        output = nonlinear_autoencoder(img)\n",
        "        loss = criterion(output, img)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n",
        "\n",
        "hidden_representations = []\n",
        "labels = []\n",
        "\n",
        "for data in testloader:\n",
        "    img, label = data\n",
        "    output = autoencoder.encoder(img.view(-1, 28 * 28))\n",
        "    hidden_representations.append(output.detach().numpy())\n",
        "    labels.append(label.numpy())\n",
        "\n",
        "hidden_representations = np.concatenate(hidden_representations, axis=0)\n",
        "labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "tsne = TSNE(n_components=2)\n",
        "hidden_tsne = tsne.fit_transform(hidden_representations)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(10):\n",
        "    plt.scatter(hidden_tsne[labels == i, 0], hidden_tsne[labels == i, 1], label=str(i))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "llpdBuOlp4sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umLjX2l2kSvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/imagenette\n",
        "!pip install torchvision\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/imagenette/imagenette2-160.tgz', 'r:gz') as tar:\n",
        "    tar.extractall('/content/named_folders/imagenet-100')\n"
      ],
      "metadata": {
        "id": "qlMiU66ggzrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "!mkdir imagenet\n",
        "# Define the path to the ImageNet data\n",
        "data_path = './imagenet/'\n",
        "\n",
        "# Define the subset of classes to use\n",
        "classes = ['cat', 'dog', 'bird']\n",
        "\n",
        "# Create a PyTorch dataset using the ImageFolder class\n",
        "dataset = datasets.ImageFolder(root=data_path, \n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                         std=[0.229, 0.224, 0.225])\n",
        "                                ]), \n",
        "                                target_transform=lambda x: classes.index(os.path.basename(os.path.dirname(x))))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset)-500, 500])\n"
      ],
      "metadata": {
        "id": "oMLdFl7-d-iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the ImageNet dataset\n",
        "train_dataset = datasets.ImageNet(root='imagenet', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset.download()\n"
      ],
      "metadata": {
        "id": "RL1scFrwd-qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='path/to/imagenet/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='path/to/imagenet/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "6Q7kAh-CdLaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "id": "c_lFTgLKbEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, noise_std):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = noise_std * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "x = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float().div(255).to(device)\n",
        "\n",
        "\n",
        "n_samples = 100\n",
        "noise_std = 0.1\n",
        "\n",
        "y_smooth = randomized_smoothing(x, model, n_samples, noise_std)\n",
        "pred_label = torch.argmax(y_smooth).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ],
      "metadata": {
        "id": "PxkJUxMYapTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the standard deviation of the Gaussian noise\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the number of samples for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the batch size for evaluation\n",
        "batch_size = 64\n",
        "\n",
        "# Define the device to run the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the ImageNet dataset with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./imagenet/train', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train a ResNet50 model on the dataset\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "for epoch in range(10):\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "testset = torchvision.datasets.ImageFolder(root='./imagenet/val', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "total, correct = 0, 0\n",
        "for i, (inputs, labels) in enumerate(testloader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = smoothed_classifier(inputs, model, n_samples, sigma)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the smoothed classifier on the test set: %.2f%%' % accuracy)\n"
      ],
      "metadata": {
        "id": "cixok1QycKiA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}