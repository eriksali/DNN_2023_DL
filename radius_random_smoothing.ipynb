{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eriksali/DNN_2023_DL/blob/main/radius_random_smoothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17ahZXHaocL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Cs8aS9N-wLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Define the dataset transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the training dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# Define the neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv7 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv8 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(7 * 7 * 512, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.pool(F.relu(self.conv6(x)))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.pool(F.relu(self.conv8(x)))\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "'''def train(net, trainloader, criterion, optimizer, device, sigma):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate Gaussian noise with variance sigma\n",
        "        noise = torch.randn_like(inputs) * sigma\n",
        "\n",
        "        # Add noise to the inputs\n",
        "        inputs_noisy = inputs + noise\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs_noisy)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(trainloader)'''\n",
        "\n",
        "\n",
        "# Define the evaluation function with input-dependent certification\n",
        "def eval(model, device, test_loader, epsilon, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = 10\n",
        "    smoothing = int(np.ceil(epsilon * 255))\n",
        "    for data, target in test_loader(batch_size=32):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        with torch.no_grad():\n",
        "            # Generate a random smoothing matrix\n",
        "            if smoothing > 0:\n",
        "                smooth = torch.zeros_like(data).float()\n",
        "                smooth.normal_(0, smoothing)\n",
        "                data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "            else:\n",
        "                data_smooth = data\n",
        "            # Predict the class labels\n",
        "            output = model(data_smooth)\n",
        "            # Compute the loss\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            # Compute the accuracy\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "    # Compute the certification accuracy\n",
        "    cert_acc = 0.0\n",
        "    for c in range(num_classes):\n",
        "        for data, target in test_loader(batch_size=32):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            with torch.no_grad():\n",
        "                # Generate a random smoothing matrix\n",
        "                if smoothing > 0:\n",
        "                    smooth = torch.zeros_like(data).float()\n",
        "                    smooth.normal_(0, smoothing)\n",
        "                    data_smooth = torch.clamp(data + smooth, 0, 1)\n",
        "                else:\n",
        "                    data_smooth = data\n",
        "                # Predict the class labels\n",
        "                output = model(data_smooth)\n",
        "                # Compute the robustness margin\n",
        "                margin = output[:, c] - torch.max(output[:, torch.arange(num_classes) != c], axis=1)[0]\n",
        "                # Compute the certification accuracy\n",
        "                correct_c = (margin >= -epsilon).sum().item()\n",
        "                cert_acc += correct_c\n",
        "    cert_acc /= num_classes * len(test_loader.dataset)\n",
        "    # Print the results\n",
        "    print('Test Loss: {:.6f}, Accuracy: {:.4f}%, Cert Accuracy: {:.4f}%'.format(\n",
        "        test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc))\n",
        "    return test_loss / len(test_loader.dataset), 100. * correct / total, 100. * cert_acc\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "# Define the device and hyperparameters\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "lr = 0.001\n",
        "momentum = 0.9\n",
        "weight_decay = 0.0005\n",
        "epsilon = 0.05\n",
        "num_iterations = 10\n",
        "\n",
        "# Load the dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the neural network model, optimizer, and loss function\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    \n",
        "# Define the training function\n",
        "def train(model, device, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "        _, predicted = output.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = 100. * correct / len(train_loader.dataset)\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "# Randomly sample Gaussian noise as the smoothing noise\n",
        "def sample_noise(image):\n",
        "    noise = torch.randn_like(image) * radius\n",
        "    return noise\n",
        "\n",
        "# Compute the average score of the randomized model over multiple iterations\n",
        "def randomized_score(images, labels):\n",
        "    total_score = torch.zeros(len(images), num_classes).to(device)\n",
        "    for i in range(num_iterations):\n",
        "        noise = sample_noise(images)\n",
        "        noisy_images = torch.clamp(images + noise, 0.0, 1.0)\n",
        "        output = model(noisy_images)\n",
        "        total_score += F.softmax(output, dim=1)\n",
        "    return total_score / num_iterations\n",
        "\n",
        "total_loss = 0.0\n",
        "total_acc = 0.0\n",
        "total_cert_acc = 0.0\n",
        "total_cert_radius = 0.0\n",
        "total_cert_rate = 0.0\n",
        "total_cert_correct = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Compute the regular loss\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        total_loss += loss.item() * len(images)\n",
        "        _, predicted = output.max(1)\n",
        "        total_acc += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Compute the randomized smoothing loss\n",
        "        randomized_scores = randomized_score(images, labels)\n",
        "        randomized_predicted = randomized_scores.max(1)[1]\n",
        "        cert_indices = randomized_predicted.eq(predicted)\n",
        "        cert_images = images[cert_indices]\n",
        "        cert_labels = labels[cert_indices]\n",
        "        cert_scores = randomized_scores[cert_indices]\n",
        "        cert_radius = torch.norm(sample_noise(cert_images).view(len(cert_images), -1), dim=1).mean()\n",
        "        cert_correct = cert_scores.max(1)[1].eq(cert_labels).sum().item()\n",
        "        cert_acc = cert_correct / len(cert_images) if len(cert_images) > 0 else 0.0\n",
        "        cert_rate = len(cert_images) / len(images)\n",
        "\n",
        "        total_cert_acc += cert_acc\n",
        "        total_cert_radius += cert_radius\n",
        "        total_cert_rate += cert_rate\n",
        "        total_cert_correct += cert_correct\n",
        "\n",
        "num_images = len(test_loader.dataset)\n",
        "avg_loss = total_loss / num_images\n",
        "avg_acc = total_acc / num_images\n",
        "avg_cert_acc = total_cert_acc / num_images\n",
        "avg_cert_radius = total_cert_radius / num_images\n",
        "avg_cert_rate = total_cert_rate / num_images\n",
        "avg_cert_correct = total_cert_correct / num_images\n",
        "\n",
        "print('Regular test accuracy: %.2f%%' % (avg_acc * 100))\n",
        "print('Certified test accuracy: %.2f%%' % (avg_cert_acc * 100))\n",
        "print('Average certified radius: %.4f' % avg_cert_radius)\n",
        "print('Certification rate: %.2f%%' % (avg_cert_rate * 100))\n",
        "print('Average number of correct labels within certified radius: %.2f' % avg_cert_correct)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train(model, device, trainloader, optimizer, criterion)\n",
        "\n",
        "# Evaluate the model with input-dependent certification\n",
        "eval(model, device, test_loader, criterion, num_classes=10, radius=0.1, num_iterations=5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "mJ4P6kDi-wP1",
        "outputId": "d59a8766-9797-4311-dcec-ff727bc652a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e5e57a9586be>\u001b[0m in \u001b[0;36m<cell line: 200>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Compute the regular loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (128) to match target batch_size (32)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This code trains the neural network f using randomized smoothing with Gaussian data augmentation at variance σ2=0.25. In each epoch, it first generates smoothed labels for each input image in the training set and then performs forward and backward passes to update the model parameters using the cross-entropy loss between the predicted and smoothed labels. It then evaluates the model on the validation set by computing the accuracy of the smoothed classifier g that is defined using f and σ2=0.25. \n",
        "The training progress is printed for each epoch, and the final accuracy on the validation set is also displayed.\n",
        "'''\n",
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n"
      ],
      "metadata": {
        "id": "MT2ybcnUgdww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "def input_dependent_certification(x, f, sigma, k):\n",
        "    \"\"\"\n",
        "    Apply input-dependent certification to a given input image x.\n",
        "    \n",
        "    Args:\n",
        "        x (torch.Tensor): Input image tensor of shape (C, H, W).\n",
        "        f (nn.Module): PyTorch model.\n",
        "        sigma (float): Standard deviation of the noise distribution.\n",
        "        k (int): Number of samples for the Monte Carlo estimator.\n",
        "        \n",
        "    Returns:\n",
        "        (bool, float): Tuple containing a boolean indicating whether the input is certified, and a float containing the \n",
        "                       certified radius.\n",
        "    \"\"\"\n",
        "    n_dims = x.ndimension()\n",
        "    x_perturb = sigma * torch.randn((k, *x.shape)).to(x.device)\n",
        "    x_perturb = x_perturb.view(k, -1)  # Flatten noise tensor\n",
        "    x_perturb = x_perturb + x.view(1, -1)  # Add noise to input tensor\n",
        "    x_perturb = x_perturb.view(k, *x.shape)  # Restore original shape of noise tensor\n",
        "\n",
        "    logits_perturb = f(x_perturb)  # Compute logits with perturbed inputs\n",
        "    preds_perturb = F.softmax(logits_perturb, dim=-1)  # Compute softmax probabilities\n",
        "\n",
        "    # Compute confidence using Monte Carlo estimator\n",
        "    preds_perturb = preds_perturb.transpose(0, 1)  # Transpose to match shape with confidence\n",
        "    confidence = preds_perturb.median(dim=1)[0]\n",
        "    radius = confidence * sigma * k**-0.5  # Compute certified radius\n",
        "\n",
        "    is_certified = (radius.max() > 0.5)  # Check if input is certified\n",
        "    return is_certified, radius.max().item()\n",
        "\n",
        "# Load Imagenette2 dataset\n",
        "test_dir = '/content/imagenette2-160/val/'\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "test_dataset = ImageFolder(test_dir, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Load pre-trained model\n",
        "model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
        "model.fc = torch.nn.Linear(512, 10)\n",
        "model.load_state_dict(torch.load('/content/model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate input-dependent certification\n",
        "correct = 0\n",
        "total = 0\n",
        "sigma = 1.0\n",
        "k = 1000\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    is_certified, radius = input_dependent_certification(images[0], model, sigma, k)\n",
        "    if is_certified and radius >= 0.5:\n",
        "        preds = model(images)\n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "        total += 1\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy:', 100 * correct / total)\n"
      ],
      "metadata": {
        "id": "WRNxldbTvVdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6E-KaaavVha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='imagenette2/train')\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val')\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 10) # Change the output size to match the number of classes in Imagenette2 (10)\n",
        "model = model.cuda()\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "def randomized_smoothing(x, f, sigma, k):\n",
        "    \"\"\"\n",
        "    Apply randomized smoothing to a given input image x.\n",
        "    \n",
        "    Args:\n",
        "        x (torch.Tensor): Input image tensor of shape (C, H, W).\n",
        "        f (nn.Module): PyTorch model.\n",
        "        sigma (float): Standard deviation of the noise distribution.\n",
        "        k (int): Number of samples for Monte Carlo estimation.\n",
        "        \n",
        "    Returns:\n",
        "        (bool): True if the input is certified to be robust to adversarial perturbations\n",
        "                within the given noise level sigma.\n",
        "    \"\"\"\n",
        "    # Generate k random noise samples of shape (C, H, W)\n",
        "    noise = torch.randn((k,) + x.shape) * sigma\n",
        "    \n",
        "    # Apply the model to the noisy samples\n",
        "    logits = f(x.unsqueeze(0).cuda() + noise.cuda()).cpu()\n",
        "    \n",
        "    # Calculate the softmax probabilities\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    \n",
        "    # Calculate the expected probability of the true class\n",
        "    p_true = probs[:, torch.argmax(probs)]\n",
        "    p_true = torch.mean(p_true)\n",
        "    \n",
        "    # Calculate the probability of the most likely incorrect class\n",
        "    p_wrong = torch.max(probs[:, torch.arange(probs.shape[1]) != torch.argmax(probs)], dim=-1).values\n",
        "    p_wrong = torch.mean(p_wrong)\n",
        "    \n",
        "    # Return True if the input is certified to be robust to adversarial perturbations\n",
        "    return p_true > p_wrong\n",
        "\n",
        "def input_dependent_certification(x, f, sigma, k):\n",
        "    \"\"\"\n",
        "    Apply input-dependent certification to a given input image x.\n",
        "    \n",
        "    Args:\n",
        "        x (torch.Tensor): Input image tensor of shape (C, H, W).\n",
        "        f (nn.Module): PyTorch model.\n",
        "        sigma (float): Standard deviation of the noise distribution.\n",
        "        k (int): Number of samples used to compute the certified lower bound.\n",
        "    Returns:\n",
        "    float: Certified lower bound for the L2 norm of the perturbation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a batch of k noisy samples\n",
        "    noises = torch.randn(k, x.shape[0], x.shape[1], x.shape[2]) * sigma\n",
        "    noisy_samples = x.unsqueeze(0) + noises\n",
        "\n",
        "    # Evaluate the model on the noisy samples\n",
        "    f_noisy = f(noisy_samples)\n",
        "\n",
        "    # Compute the predicted class for the clean image\n",
        "    f_clean = f(x.unsqueeze(0))\n",
        "    y_pred = torch.argmax(f_clean, dim=1)\n",
        "\n",
        "    # Compute the predicted class for the noisy samples\n",
        "    f_noisy_max, _ = torch.max(f_noisy, dim=1)\n",
        "    y_noisy_pred = torch.argmax(f_noisy_max, dim=1)\n",
        "\n",
        "    # Compute the number of incorrect predictions on the noisy samples\n",
        "    num_errors = torch.sum(y_noisy_pred != y_pred)\n",
        "\n",
        "    # Compute the certified lower bound\n",
        "    delta = torch.sqrt(torch.tensor(num_errors / k))\n",
        "    c = 1.0 / (2 * math.pi * delta * sigma)\n",
        "    return c * torch.norm(noises)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CjjsTDEWuKbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import math\n",
        "\n",
        "\n",
        "# Load the Imagenette2 dataset\n",
        "traindir = '/content/imagenette2/train'\n",
        "valdir = '/content/imagenette2/val'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(traindir, transforms.Compose([\n",
        "        transforms.RandomResizedCrop(160),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(192),\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(Net, self).__init__()\n",
        "        self.device = device\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 20 * 20, 1024)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.squeeze(0)  # remove the first dimension (batch size)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 20 * 20)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "'''\n",
        "# Define the model architecture and hyperparameters\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(Net, self).__init__()\n",
        "        self.device = device\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 20 * 20, 1024)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 20 * 20)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "'''\n",
        "\n",
        "class SmoothCert:\n",
        "    def __init__(self, model, num_classes, sigma):\n",
        "        self.model = model\n",
        "        self.num_classes = num_classes\n",
        "        self.sigma = sigma\n",
        "\n",
        "\n",
        "    def smooth_max(self, x, sigma):\n",
        "        \"\"\"\n",
        "        SmoothMax function implementation\n",
        "        \"\"\"\n",
        "        x_sort, _ = torch.sort(x, descending=True)\n",
        "        cum_sum = torch.cumsum(x_sort, dim=0)\n",
        "        t = torch.arange(1, x_sort.size(0) + 1, device=x_sort.device)\n",
        "        rho = torch.where((x_sort - (cum_sum - sigma) / t) > 0, t, torch.zeros_like(t))\n",
        "        rho_max = torch.max(rho)\n",
        "        w = torch.clamp((cum_sum - sigma) / rho_max, min=0)\n",
        "        return w\n",
        "\n",
        "    def certify(self, x, epsilon):\n",
        "        \"\"\"\n",
        "        Given input `x` and perturbation budget `epsilon`, computes\n",
        "        the upper bound of the maximum logit value among all classes\n",
        "        using SmoothMax certification\n",
        "        \"\"\"\n",
        "        x = x.unsqueeze(0)\n",
        "        x = x.to(device=self.model.device, dtype=torch.float32)\n",
        "        num_samples = 5000\n",
        "        perturbations = torch.randn((num_samples,) + x.shape[1:], device=self.model.device) * epsilon\n",
        "        perturbations = perturbations.to(dtype=torch.float32)\n",
        "\n",
        "        # Create noisy samples and compute logits for each sample\n",
        "        perturbed_inputs = x + perturbations\n",
        "        logits = self.model(perturbed_inputs)\n",
        "        max_logits, _ = logits.max(dim=1)\n",
        "\n",
        "        # Compute SmoothMax of the logits\n",
        "        smooth_max_logits = self.smooth_max(max_logits, self.sigma)\n",
        "\n",
        "        # Compute the maximum of the SmoothMax logits\n",
        "        smooth_max_logits_max = smooth_max_logits.max()\n",
        "\n",
        "        # Return the SmoothMax certified upper bound\n",
        "        return smooth_max_logits_max - epsilon * torch.norm(self.model.weight.view(-1), p=2) / x.numel()**0.5\n",
        "\n",
        "# Load the pretrained model\n",
        "##model = Net()\n",
        "# Load the pretrained model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net(device=device)\n",
        "\n",
        "##model.load_state_dict(torch.load('model.pt'))\n",
        "##model.to(device='cuda')\n",
        "\n",
        "# Initialize the SmoothCert object with sigma=0.1\n",
        "sigma = 0.1\n",
        "smooth_cert = SmoothCert(model, num_classes=10, sigma=sigma)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Load an example image from the validation set\n",
        "##val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "x, y_true = next(iter(val_loader))\n",
        "\n",
        "# Certify the example image with a perturbation budget of epsilon=0.1\n",
        "epsilon = 0.1\n",
        "certified_upper_bound = smooth_cert.certify(x, epsilon)\n",
        "\n",
        "print(\"Certified upper bound:\", certified_upper_bound.item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "nWUv6jwhnUk5",
        "outputId": "1d79922f-600c-4054-b87b-6d74aa769003"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-04a61d1e6b6b>\u001b[0m in \u001b[0;36m<cell line: 198>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;31m# Certify the example image with a perturbation budget of epsilon=0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m \u001b[0mcertified_upper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth_cert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcertify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Certified upper bound:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcertified_upper_bound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-04a61d1e6b6b>\u001b[0m in \u001b[0;36mcertify\u001b[0;34m(self, x, epsilon)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Create noisy samples and compute logits for each sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mperturbed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mperturbations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mmax_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-04a61d1e6b6b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# remove the first dimension (batch size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [5000, 1, 3, 160, 160]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages and libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "import math\n",
        "\n",
        "# Load the Imagenette2 dataset\n",
        "traindir = '/content/imagenette2/train'\n",
        "valdir = '/content/imagenette2/val'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(traindir, transforms.Compose([\n",
        "        transforms.RandomResizedCrop(160),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(192),\n",
        "        transforms.CenterCrop(160),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "# Define the model architecture and hyperparameters\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 20 * 20, 1024)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 20 * 20)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SmoothCert:\n",
        "    def __init__(self, model, num_classes, sigma):\n",
        "        self.model = model\n",
        "        self.num_classes = num_classes\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def smooth(self, x, y):\n",
        "        n = x.size(0)\n",
        "        dim = x.size()[1:]\n",
        "        y_onehot = torch.zeros(n, self.num_classes).to(x.device)\n",
        "        y_onehot.scatter_(1, y.view(-1, 1), 1)\n",
        "\n",
        "        L = self._compute_lipschitz(x)\n",
        "        r = self.sigma * L\n",
        "        noise = torch.randn_like(x) * r.view(n, 1, 1, 1)\n",
        "\n",
        "        x_noisy = x + noise\n",
        "        logits = self.model(x_noisy)\n",
        "        logits_smooth = self._average_logits(logits, noise)\n",
        "\n",
        "        return logits_smooth, y_onehot, r\n",
        "\n",
        "    def _average_logits(self, logits, noise):\n",
        "        logits = logits / self.sigma ** 2\n",
        "        noise_norm = noise.norm(p=2, dim=(1, 2, 3))\n",
        "        noise_norm = noise_norm.view(-1, 1, 1, 1)\n",
        "        logits -= noise_norm * self.model.fc2.weight.view(1, self.num_classes, 1, 1)\n",
        "        return logits.mean(dim=0)\n",
        "\n",
        "    def _compute_lipschitz(self, x, eps=1e-5, n_iter=20):\n",
        "        n = x.size(0)\n",
        "        with torch.no_grad():\n",
        "            x = x.repeat_interleave(self.num_classes, dim=0)\n",
        "            x.requires_grad_()\n",
        "            y = torch.arange(self.num_classes).repeat(n)\n",
        "            y = y.to(x.device)\n",
        "            logits = self.model(x)\n",
        "            loss = F.cross_entropy(logits, y, reduction='none')\n",
        "            grad = torch.autograd.grad(loss.sum(), x)[0]\n",
        "            norm = grad.view(n, self.num_classes, -1).norm(p=2, dim=-1)\n",
        "            lipschitz = norm.max(dim=1)[0] / eps\n",
        "        return lipschitz\n",
        "\n",
        "\n",
        "model = AlexNet(num_classes=10).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "f = train(model, optimizer, scheduler, train_loader, val_loader, num_epochs=10, sigma=0.5)\n",
        "\n",
        "cert_acc = evaluate(f, val_loader, SmoothCert(f, num_classes=10, sigma=0.5), num_classes=10)\n",
        "print(\"Certified accuracy: {:.2f}%\".format(100 * cert_acc))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "2Pf0YlBKlWkJ",
        "outputId": "182ad7de-bb5a-467b-ff08-7a2ea36a0bbe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-998915bb8f8d>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AlexNet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mOWNIB8lWnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ndj4mfWxlWqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network f\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), 256 * 6 * 6)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Define the function to create the smoothed classifier g\n",
        "def g(x, f, sigma, num_classes):\n",
        "    n_samples = 1000\n",
        "    gaussian_noise = torch.randn(n_samples, 3, 224, 224).to(device) * sigma\n",
        "    f_x = f(x + gaussian_noise)\n",
        "    f_x = nn.functional.softmax(f_x, dim=1)\n",
        "    g_x = torch.zeros((x.shape[0], num_classes)).to(device)\n",
        "    for i in range(n_samples):\n",
        "        g_x += f_x[i] / n_samples\n",
        "    return g_x.argmax(dim=1)\n",
        "\n",
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define the dataset and data loaders\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "train_dataset = datasets.ImageFolder('imagenette2/train', data_transforms)\n",
        "val_dataset = datasets.ImageFolder('imagenette2/val', data_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "# Initialize the neural network f\n",
        "f = Net().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(f.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train the neural network f\n",
        "num_epochs = 1\n",
        "num_classes= 10\n",
        "sigma = 0.5\n",
        "for epoch in range(num_epochs):\n",
        "    f.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate smoothed labels\n",
        "        smoothed_labels = torch.zeros(inputs.size(0), num_classes, device=device)\n",
        "        for j in range(num_classes):\n",
        "            smoothed_labels[:, j] = (targets == j).float()\n",
        "        smoothed_labels = (1 - sigma) * smoothed_labels + (sigma / num_classes)\n",
        "\n",
        "        # Perform forward and backward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = f(inputs)\n",
        "        loss = criterion(outputs, smoothed_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Print progress\n",
        "        if i % 10 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, len(train_loader), running_loss / (i+1)))\n",
        "\n",
        "    # Evaluate performance on validation set\n",
        "    f.eval()\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for x, y in val_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = g(x, f, sigma, num_classes)\n",
        "        num_correct += (pred == y).sum()\n",
        "        num_samples += pred.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Accuracy on validation set: {:.2f}%\\n'.format(acc*100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "8nOWhWA7geiP",
        "outputId": "22231b41-93af-4acd-862f-f8cccab452f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [1/296], Loss: 2.3027\n",
            "Epoch [1/1], Step [11/296], Loss: 2.3029\n",
            "Epoch [1/1], Step [21/296], Loss: 2.3028\n",
            "Epoch [1/1], Step [31/296], Loss: 2.3027\n",
            "Epoch [1/1], Step [41/296], Loss: 2.3027\n",
            "Epoch [1/1], Step [51/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [61/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [71/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [81/296], Loss: 2.3024\n",
            "Epoch [1/1], Step [91/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [101/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [111/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [121/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [131/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [141/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [151/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [161/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [171/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [181/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [191/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [201/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [211/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [221/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [231/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [241/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [251/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [261/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [271/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [281/296], Loss: 2.3025\n",
            "Epoch [1/1], Step [291/296], Loss: 2.3024\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-36fe01386145>\u001b[0m in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mnum_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-36fe01386145>\u001b[0m in \u001b[0;36mg\u001b[0;34m(x, f, sigma, num_classes)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mgaussian_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mf_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgaussian_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mf_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mg_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (1000) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zNZBqWggenY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def smooth_one_hot(y, num_classes, smoothing=0.0):\n",
        "    one_hot = torch.zeros_like(y).scatter(1, y.unsqueeze(1), 1)\n",
        "    return one_hot * (1 - smoothing) + smoothing / num_classes\n",
        "\n",
        "def smooth_predictions(f, x, sigma, num_classes, smoothing=0.0):\n",
        "    n = x.shape[0]\n",
        "    noise = torch.randn(n, num_classes) * sigma\n",
        "    logits = f(x + noise)\n",
        "    targets = torch.argmax(logits, dim=1)\n",
        "    one_hot = smooth_one_hot(targets, num_classes, smoothing=smoothing)\n",
        "    return one_hot\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "sigma = 0.1  # choose a value for the noise standard deviation\n",
        "num_classes = 1000  # this is the number of classes in ImageNet\n",
        "\n",
        "f = alexnet(num_classes=num_classes)\n",
        "optimizer = optim.SGD(f.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    f.train()\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x = x + torch.randn_like(x) * sigma  # add random noise to the input\n",
        "        output = f(x)\n",
        "        loss = F.cross_entropy(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def g(x, f, sigma, num_classes, smoothing=0.0):\n",
        "    f.eval()\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    for x, y in val_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = g(x, f, sigma, num_classes)\n",
        "        num_correct += (pred == y).sum()\n",
        "        num_samples += x.size(0)\n",
        "\n",
        "acc = float(num_correct) / num_samples\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "id": "_v-dt6HqeHKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network f\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define a function to train the network\n",
        "def train(net, trainloader, criterion, optimizer, device, sigma):\n",
        "    net.train()\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        noisy_inputs = inputs + sigma * torch.randn_like(inputs)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(noisy_inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define a function to test the network on clean inputs\n",
        "def test(net, testloader, device, sigma):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            noisy_inputs = inputs + sigma * torch.randn_like(inputs)\n",
        "            outputs = net(noisy_inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Set up the data loaders and transforms\n",
        "traindir = 'imagenet_subset/train'\n",
        "valdir = 'imagenet_subset/val'\n",
        "train_dataset = datasets.ImageFolder(traindir, transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "       \n"
      ],
      "metadata": {
        "id": "ZGsMKU_3cHky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "traindir = 'imagenette2'\n",
        "valdir = 'imagenette2'\n",
        "train_dataset = datasets.ImageFolder(traindir, transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.Resize((138, 184)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]))\n",
        "\n",
        "def smooth_predictions(net, inputs, sigma, num_classes=10, num_samples=100):\n",
        "    outputs = torch.zeros((inputs.shape[0], num_classes))\n",
        "    for i in range(num_samples):\n",
        "        noisy_inputs = inputs + sigma * torch.randn_like(inputs)\n",
        "        noisy_outputs = net(noisy_inputs)\n",
        "        outputs += noisy_outputs\n",
        "    outputs /= num_samples\n",
        "    return outputs\n",
        "\n",
        "def smoothed_predictions(net, dataloader, device, sigma):\n",
        "    net.eval()\n",
        "    all_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = smooth_predictions(net, inputs, sigma)\n",
        "            all_outputs.append(outputs.cpu().numpy())\n",
        "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
        "    return all_outputs\n",
        "\n",
        "def smoothed_predictions_labels(net, dataloader, device, sigma):\n",
        "    all_outputs = smoothed_predictions(net, dataloader, device, sigma)\n",
        "    predicted_labels = np.argmax(all_outputs, axis=1)\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Define the neural network f\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "'''net_f = Net()\n",
        "net_f.to(device)'''\n",
        "\n",
        "f = Net()\n",
        "f = f.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(f.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "for epoch in range(100):\n",
        "    train(f, trainloader, criterion, optimizer, device, sigma=0.1)\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "g = Net()\n",
        "g = g.to(device)\n",
        "g.load_state_dict(f.state_dict())\n",
        "\n",
        "def predict_smoothed(net, inputs, sigma):\n",
        "    smoothed_outputs = smooth_predictions(net, inputs, sigma)\n",
        "    predicted_labels = np.argmax(smoothed_outputs.cpu().numpy(), axis=1)\n",
        "    return predicted_labels\n",
        "\n",
        "def predict(net, inputs):\n",
        "    outputs = net(inputs)\n",
        "    predicted_labels = np.argmax(outputs.cpu().numpy(), axis=1)\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "f_accuracy = test(f, testloader, device, sigma=0)\n",
        "g_accuracy = test_smoothed(g, testloader, device, sigma=0.1)\n",
        "print(\"Accuracy of f: {:.}%, Accuracy of g: {:.2f}%\".format(100 * f_accuracy, 100 * g_accuracy))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "tz5PBLmUYgkc",
        "outputId": "b955b751-2787-46b8-e38b-976f29fabbcf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9cb6eb139821>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-cc641c596237>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, criterion, optimizer, device, sigma)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 163, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 500, 393] at entry 0 and [3, 333, 500] at entry 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEN9GWyjYgoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.RandomResizedCrop(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                           std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                      transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                           std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "!pip install torchvision\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset = datasets.ImageFolder(root='imagenette2/train', transform=transforms.ToTensor())\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val', transform=transforms.ToTensor())\n",
        "\n",
        "# Define the data loaders\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the neural network f\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net_f = Net()\n",
        "net_f.to(device)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net_f.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network f with Gaussian data augmentation at variance σ2\n",
        "num_epochs = 10\n",
        "sigma = 0.5\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(net_f, trainloader, criterion, optimizer, device, sigma)\n",
        "    test_acc = test(net_f, testloader, device, sigma)\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Test Accuracy: {:.2f}%'\n",
        "          .format(epoch+1, num_epochs, train_loss, test_acc))\n",
        "\n",
        "'''# Define the smoothed classifier g\n",
        "class SmoothClassifier(nn.Module):\n",
        "    def __init__(self, base_classifier, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.base_classifier = base_classifier\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def forward(self, x):\n",
        "        num_samples = 1000\n",
        "        noise = torch.randn(num_samples, *x.size()).to(device) * self.sigma\n",
        "        perturbed_inputs = x + noise\n",
        "        # Average the predictions of the base classifier on the perturbed inputs\n",
        "        predictions = torch.zeros(num_samples, x.size(0)).to(device)\n",
        "        for i in range(num_samples):\n",
        "            predictions[i] = self.base_classifier(perturbed_inputs[i])\n",
        "        smoothed_predictions = torch.mean(predictions, dim=0)\n",
        "\n",
        "        return smoothed_predictions\n",
        "\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "'''\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        n_samples = 1000\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n"
      ],
      "metadata": {
        "id": "Y7SmBgfZU_7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PT2nkpg9p2y6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "c590c9db-d557-47c1-ca0c-b437a519559f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cc641c596237>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}, Train Loss: {:.4f}, Test Acc: {:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-cc641c596237>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, criterion, optimizer, device, sigma)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 143, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/collate.py\", line 163, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [3, 160, 160] at entry 0 and [3, 500, 455] at entry 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.RandomResizedCrop(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                           std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "                                      transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                           std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "!pip install torchvision\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset = datasets.ImageFolder(root='imagenette2/train', transform=transforms.ToTensor())\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2/val', transform=transforms.ToTensor())\n",
        "\n",
        "# Define the data loaders\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "'''\n",
        "train_dir = '/content/train'\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "\n",
        "test_dir = '/content/test'\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)'''\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Net()\n",
        "net.to(device)\n",
        "\n",
        "\n",
        "def train(net, trainloader, criterion, optimizer, device, sigma):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate Gaussian noise with variance sigma\n",
        "        noise = torch.randn_like(inputs) * sigma\n",
        "\n",
        "        # Add noise to the inputs\n",
        "        inputs_noisy = inputs + noise\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs_noisy)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(trainloader)\n",
        "\n",
        "\n",
        "def test(net, testloader, device, sigma):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate 1000 noisy samples for each input\n",
        "        inputs_noise = []\n",
        "        for _ in range(1000):\n",
        "            noise = torch.randn_like(inputs)\n",
        "            inputs_noise.append(inputs + sigma * noise)\n",
        "\n",
        "        # Stack noisy samples and make predictions\n",
        "        inputs_noise = torch.stack(inputs_noise)\n",
        "        outputs = net(inputs_noise)\n",
        "        _, predicted = outputs.mean(0).max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Test Accuracy: {:.2f}%'.format(accuracy))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "'''# Calculate the accuracy of f on the test set\n",
        "test_acc_f = test(net_f, testloader, device, 0)\n",
        "print('Accuracy of f on the test set: {:.2f}%'.format(100 * test_acc_f))\n",
        "\n",
        "# Calculate the accuracy of g on the test set\n",
        "test_acc_g = test(net_g, testloader, device, sigma)\n",
        "print('Accuracy of g on the test set: {:.2f}%'.format(100 * test_acc_g))\n",
        "'''\n",
        "\n",
        "# Define a new function that returns the predictions of the smoothed classifier g\n",
        "def predict_smoothed(net, inputs, device, sigma):\n",
        "    net.eval()\n",
        "    inputs_noise = []\n",
        "    for _ in range(1000):\n",
        "        noise = torch.randn_like(inputs)\n",
        "        inputs_noise.append(inputs + sigma * noise)\n",
        "    inputs_noise = torch.stack(inputs_noise)\n",
        "    outputs = net(inputs_noise)\n",
        "    _, predicted = outputs.mean(0).max(1)\n",
        "    return predicted\n",
        "\n",
        "# Train the neural network f with Gaussian data augmentation at variance σ2\n",
        "net_f = Net()\n",
        "net_f.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net_f.parameters())\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train(net_f, trainloader, criterion, optimizer, device, sigma=0.1)\n",
        "    test_acc = test(net_f, testloader, device, sigma=0.1)\n",
        "    print('Epoch: {}, Train Loss: {:.4f}, Test Acc: {:.2f}%'.format(epoch+1, train_loss, test_acc))\n",
        "\n",
        "# Create the smoothed classifier g\n",
        "net_g = lambda x: predict_smoothed(net_f, x, device, sigma=0.1)\n",
        "\n",
        "# Test both classifiers on the test set\n",
        "test_acc_f = test(net_f, testloader, device, sigma=0)\n",
        "test_acc_g = test(net_g, testloader, device, sigma=0.1)\n",
        "\n",
        "# Print the results\n",
        "print('Accuracy of f on the test set: {:.2f}%'.format(test_acc_f))\n",
        "print('Accuracy of g on the test set: {:.2f}%'.format(test_acc_g))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kcki6APBjvbI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRkzVPwpjvev",
        "outputId": "9b05a492-03b6-468c-d30e-ebfa637b412e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1485M  100 1485M    0     0  38.4M      0  0:00:38  0:00:38 --:--:-- 38.3M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz\n",
        "!tar xzf imagenette2.tgz\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3PCqY8bNLqK",
        "outputId": "e163d9e5-8591-4dfd-c00d-7a6f074336bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-03 03:45:06--  http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
            "Resolving www.image-net.org (www.image-net.org)... 171.64.68.16\n",
            "Connecting to www.image-net.org (www.image-net.org)|171.64.68.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar [following]\n",
            "--2023-04-03 03:45:06--  https://image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-04-03 03:45:06 ERROR 404: Not Found.\n",
            "\n",
            "--2023-04-03 03:45:06--  http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
            "Resolving www.image-net.org (www.image-net.org)... 171.64.68.16\n",
            "Connecting to www.image-net.org (www.image-net.org)|171.64.68.16|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar [following]\n",
            "--2023-04-03 03:45:06--  https://image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-04-03 03:45:06 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar"
      ],
      "metadata": {
        "id": "gyZCcK2AN7Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Define the data transforms\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define the training and testing datasets\n",
        "trainset = torchvision.datasets.ImageNet(root='imagenette2', split='train', download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.ImageNet(root='imagenette2', split='val', download=True, transform=transform_test)\n",
        "\n",
        "# Define the training and testing data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = torch.nn.Linear(64 * 56 * 56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 56 * 56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Define the training function\n",
        "def train(net, trainloader, device, criterion, optimizer, epoch, sigma):\n",
        "    net.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Add Gaussian noise to the input\n",
        "        noise = torch.randn_like(inputs) * sigma\n",
        "        inputs = inputs + noise.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(inputs), len(trainloader.dataset),\n",
        "                100. * batch_idx / len(trainloader), loss.item()))\n",
        "\n",
        "# Define the test function\n",
        "def test(net, testloader, device, sigma):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Generate 1000 noisy samples for each input\n",
        "        inputs_noise = []\n",
        "        for _ in range(1000):\n",
        "            noise = torch.randn_like(inputs)\n",
        "\n",
        "        # Generate 1000 noisy samples for each input\n",
        "        inputs_noise = []\n",
        "        for _ in range(1000):\n",
        "            noise = torch.randn_like(inputs)\n",
        "            inputs_noise.append(inputs + sigma * noise)\n",
        "\n",
        "        inputs_noise = torch.stack(inputs_noise)\n",
        "\n",
        "        # Compute the predictions of the original network on the noisy samples\n",
        "        outputs_noise = net(inputs_noise)\n",
        "        predictions_noise = torch.argmax(outputs_noise, dim=1)\n",
        "\n",
        "        # Smooth the predictions\n",
        "        predictions_counts = torch.bincount(predictions_noise, minlength=10)\n",
        "        predictions_probs = predictions_counts / predictions_counts.sum()\n",
        "        predictions_smooth = predictions_probs.argmax()\n",
        "\n",
        "        # Evaluate the smoothed classifier\n",
        "        total += targets.size(0)\n",
        "        correct += (predictions_smooth == targets).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print('Accuracy of the smoothed classifier on the test images: %.2f %%' % acc)\n",
        "\n"
      ],
      "metadata": {
        "id": "GpJvjB2zMgRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''!pip install robustness\n",
        "!pip install datasets\n",
        "!pip install torchvision'''\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "##from robustness import model_utils, datasets, train, defaults\n",
        "from robustness.tools import folder\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='imagenette2', split='train')\n",
        "test_dataset = datasets.ImageFolder(root='imagenette2', split='val')\n",
        "\n",
        "# Define the model architecture\n",
        "model_kwargs = {\n",
        "    'arch': 'resnet50',\n",
        "    'dataset': 'imagenet',\n",
        "    'resume_path': None\n",
        "}\n",
        "model, _ = model_utils.make_and_restore_model(**model_kwargs)\n",
        "\n",
        "# Define the training parameters\n",
        "train_kwargs = {\n",
        "    'lr': 0.001,\n",
        "    'weight_decay': 0.0001,\n",
        "    'epochs': 10,\n",
        "    'out_dir': 'path/to/output/directory',\n",
        "    'adv_train': 0,\n",
        "    'constraint': None\n",
        "}\n",
        "\n",
        "# Train the model with Gaussian data augmentation\n",
        "train.train_model(train_kwargs, model, (train_dataset, test_dataset))\n",
        "\n",
        "# Create a smoothed classifier g\n",
        "from robustness.tools.label_maps import IMAGENET_LABELS\n",
        "from robustness.tools import helpers\n",
        "\n",
        "def g(x):\n",
        "    predictions = []\n",
        "    for i in range(10):\n",
        "        x_noisy = x + torch.randn_like(x) * 0.1\n",
        "        pred = model(helpers.prepare_input(x_noisy)).argmax().item()\n",
        "        predictions.append(pred)\n",
        "    return max(set(predictions), key=predictions.count)\n",
        "\n",
        "# Evaluate the performance of g on the test set\n",
        "from tqdm import tqdm\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for i, (inputs, labels) in tqdm(enumerate(test_dataset)):\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "    predictions = g(inputs)\n",
        "    if predictions == labels:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "7MtKqGttJLRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Download the ImageNet dataset subset\n",
        "train_dataset = datasets.ImageNet(root='./data', download=True, subset='train')\n",
        "\n",
        "# Download and load the smallest Imagenet dataset\n",
        "imagenet_val = datasets.ImageNet(root='path/to/imagenet', split='val', download=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s4AZMxd3HNhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLASyAu8kMEt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define hyperparameters\n",
        "##batch_size = 128\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "sigma = 0.1\n",
        "num_classes = 10\n",
        "\n",
        "# Load Imagenette2 dataset and apply data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=train_transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
        "        self.bn5 = nn.BatchNorm1d(1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.bn5(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model and train using cross-entropy loss and the Adam optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move images and labels to the device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Print statistics every 100 batches\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "            \n",
        "\n",
        "'''def generate_smoothed_predictions(model, images, labels, num_samples, sigma):\n",
        "    with torch.no_grad():\n",
        "        predictions = torch.zeros(len(images), num_classes).to(device)\n",
        "        for i in range(num_samples):\n",
        "            # Add Gaussian noise to the images\n",
        "            noisy_images = images + torch.randn_like(images) * sigma\n",
        "              \n",
        "            # Get predictions for the noisy images\n",
        "            noisy_outputs = model(noisy_images)\n",
        "            \n",
        "            # Accumulate predictions\n",
        "            predictions += F.softmax(noisy_outputs, dim=1)\n",
        "    \n",
        "    # Take the average of the predictions\n",
        "    smoothed_predictions = predictions / num_samples\n",
        "    \n",
        "    # Compute the predicted labels for the smoothed predictions\n",
        "    _, predicted_labels = smoothed_predictions.max(1)\n",
        "    \n",
        "    # Compute the accuracy of the smoothed predictions\n",
        "    accuracy = (predicted_labels == labels).sum().item() / len(labels)\n",
        "    \n",
        "    return smoothed_predictions, predicted_labels, accuracy'''\n",
        "\n",
        "def generate_smoothed_predictions(model, images, labels, num_samples, sigma, batch_size=32):\n",
        "    with torch.no_grad():\n",
        "        predictions = torch.zeros(len(images), num_classes).to(device)\n",
        "        for i in range(num_samples):\n",
        "            # Add Gaussian noise to the images\n",
        "            noisy_images = images + torch.randn_like(images) * sigma\n",
        "            \n",
        "            # Split the noisy images and labels into smaller batches\n",
        "            noisy_images_batches = torch.split(noisy_images, batch_size)\n",
        "            labels_batches = torch.split(labels, batch_size)\n",
        "            \n",
        "            # Get predictions for the noisy images\n",
        "            for noisy_images_batch, labels_batch in zip(noisy_images_batches, labels_batches):\n",
        "                noisy_outputs = model(noisy_images_batch)\n",
        "\n",
        "                # Accumulate predictions\n",
        "                predictions[labels_batch] += F.softmax(noisy_outputs, dim=1)\n",
        "    \n",
        "    # Take the average of the predictions\n",
        "    smoothed_predictions = predictions / num_samples\n",
        "    \n",
        "    # Compute the predicted labels for the smoothed predictions\n",
        "    _, predicted_labels = smoothed_predictions.max(1)\n",
        "    \n",
        "    # Compute the accuracy of the smoothed predictions\n",
        "    accuracy = (predicted_labels == labels).sum().item() / len(labels)\n",
        "    \n",
        "    return smoothed_predictions, predicted_labels, accuracy\n",
        "\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "test_correct = 0\n",
        "num_samples = 10\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Generate smoothed predictions for the images\n",
        "    smoothed_predictions, predicted_labels, accuracy = generate_smoothed_predictions(model, images, labels, num_samples, sigma)\n",
        "\n",
        "    # Accumulate the test loss and number of correct predictions\n",
        "    test_loss += criterion(smoothed_predictions, labels).item()\n",
        "    test_correct += (predicted_labels == labels).sum().item()\n",
        "\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "avg_test_accuracy = test_correct / len(test_loader.dataset)\n",
        "\n",
        "print('Test Loss: {:.4f}, Test Accuracy: {:.4f}'.format(avg_test_loss, avg_test_accuracy))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHN4FHdj6Lef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "sigma = 0.1\n",
        "num_classes = 10\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# Download the ImageNet dataset subset\n",
        "train_dataset = datasets.ImageNet(root='./data', download=True, subset='train')\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='imagenette2/train', transform=train_transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='imagenette2/val', transform=test_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
        "        self.bn5 = nn.BatchNorm1d(1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = x.view(-1, 512 * 7 * 7)\n",
        "        x = F.relu(self.bn5(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    print('Epoch: %d/%d, Train Loss: %f' % (epoch+1, num_epochs, train_loss))\n",
        "\n",
        "'''\n",
        "\n",
        "##num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "\n",
        "# create the smoothed classifier g:\n",
        "\n",
        "\n",
        "def smoothed_classifier(x, n_samples):\n",
        "    model.eval()\n",
        "\n",
        "    logits_list = []\n",
        "    for i in range(n_samples):\n",
        "        logits = model(x + sigma * torch.randn_like(x))\n",
        "        logits_list.append(logits.unsqueeze(0))\n",
        "\n",
        "    logits_stack = torch.cat(logits_list, dim=0)\n",
        "    avg_logits = logits_stack.mean(dim=0)\n",
        "    return avg_logits.argmax(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "num_samples = 30\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = smoothed_classifier(images, num_samples)\n",
        "        total += labels.size(0)\n",
        "        correct += (outputs == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the smoothed classifier on the test images: %f %%' % (100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "id": "BRlT_s2W6MNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvQZOk7nkSqU",
        "outputId": "e6b1031b-df76-496a-fe61-2871318c1077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Loss = 2.5759711458876327\n",
            "Epoch 2: Loss = 1.6562320445034955\n"
          ]
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "'''import torchvision.datasets as datasets\n",
        "\n",
        "imagenette = datasets.ImageFolder('imagenette2/train')'''\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='imagenette2/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='imagenette2/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srjCCDgnp36x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llpdBuOlp4sQ"
      },
      "outputs": [],
      "source": [
        "# 1.7 \n",
        "# Repeat the autoencoder steps with a nonlinear autoencoder and compare the results against PCA and linear encoder.\n",
        "\n",
        "!pip install torch numpy matplotlib sklearn\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "trainset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "class NonlinearAutoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NonlinearAutoencoder, self).__init__()\n",
        "        self.encoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(28 * 28, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 10)\n",
        "        )\n",
        "        self.decoder = torch.nn.Sequential(\n",
        "            torch.nn.Linear(10, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 28 * 28),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        x = x.view(-1, 1, 28, 28)\n",
        "        return x\n",
        "\n",
        "nonlinear_autoencoder = NonlinearAutoencoder()\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nonlinear_autoencoder.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for data in trainloader:\n",
        "        img, _ = data\n",
        "        optimizer.zero_grad()\n",
        "        output = nonlinear_autoencoder(img)\n",
        "        loss = criterion(output, img)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 10, loss.item()))\n",
        "\n",
        "hidden_representations = []\n",
        "labels = []\n",
        "\n",
        "for data in testloader:\n",
        "    img, label = data\n",
        "    output = autoencoder.encoder(img.view(-1, 28 * 28))\n",
        "    hidden_representations.append(output.detach().numpy())\n",
        "    labels.append(label.numpy())\n",
        "\n",
        "hidden_representations = np.concatenate(hidden_representations, axis=0)\n",
        "labels = np.concatenate(labels, axis=0)\n",
        "\n",
        "tsne = TSNE(n_components=2)\n",
        "hidden_tsne = tsne.fit_transform(hidden_representations)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(10):\n",
        "    plt.scatter(hidden_tsne[labels == i, 0], hidden_tsne[labels == i, 1], label=str(i))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umLjX2l2kSvO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlMiU66ggzrv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/fastai/imagenette\n",
        "!pip install torchvision\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/imagenette/imagenette2-160.tgz', 'r:gz') as tar:\n",
        "    tar.extractall('/content/named_folders/imagenet-100')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMLdFl7-d-iA"
      },
      "outputs": [],
      "source": [
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar\n",
        "!tar -xvf ILSVRC2012_img_train.tar\n",
        "\n",
        "!wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar\n",
        "!tar -xvf ILSVRC2012_img_val.tar\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "!mkdir imagenet\n",
        "# Define the path to the ImageNet data\n",
        "data_path = './imagenet/'\n",
        "\n",
        "# Define the subset of classes to use\n",
        "classes = ['cat', 'dog', 'bird']\n",
        "\n",
        "# Create a PyTorch dataset using the ImageFolder class\n",
        "dataset = datasets.ImageFolder(root=data_path, \n",
        "                                transform=transforms.Compose([\n",
        "                                    transforms.Resize(256),\n",
        "                                    transforms.CenterCrop(224),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                                         std=[0.229, 0.224, 0.225])\n",
        "                                ]), \n",
        "                                target_transform=lambda x: classes.index(os.path.basename(os.path.dirname(x))))\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len(dataset)-500, 500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL1scFrwd-qU"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the ImageNet dataset\n",
        "train_dataset = datasets.ImageNet(root='imagenet', split='train', transform=transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "# Download the dataset\n",
        "train_dataset.download()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q7kAh-CdLaV"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "This code will evaluate the smoothed classifier on the test set and print out the test accuracy. \n",
        "Note that this may take some time to run, depending on the size of the test set and the number of samples used for smoothing.\n",
        "'''\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Gaussian data augmentation function\n",
        "def gaussian_noise(image, sigma):\n",
        "    return image + torch.randn_like(image) * sigma\n",
        "\n",
        "# Define the dataset class for ImageNet\n",
        "class ImageNetDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.transform = transform\n",
        "        self.dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[index]\n",
        "        image = gaussian_noise(image, sigma)\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Load the ImageNet dataset\n",
        "transform = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_dataset = ImageNetDataset(root='path/to/imagenet/train', transform=transform)\n",
        "test_dataset = ImageNetDataset(root='path/to/imagenet/val', transform=transform)\n",
        "\n",
        "# Define the neural network f and train it\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = torch.nn.Linear(64*56*56, 512)\n",
        "        self.fc2 = torch.nn.Linear(512, 1000)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64*56*56)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Loss = {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Define the smoothed classifier g\n",
        "class SmoothClassifier(torch.nn.Module):\n",
        "    def __init__(self, f, sigma):\n",
        "        super(SmoothClassifier, self).__init__()\n",
        "        self.f = f\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def forward(self, x):\n",
        "        logits = torch.zeros((len(x), 1000)).to(device)\n",
        "        for i in range(n_samples):\n",
        "            noise = self.sigma * torch.randn_like(x).to(device)\n",
        "            logits += self.f(x + noise)\n",
        "        return logits / n_samples\n",
        "\n",
        "sigma = 0.1\n",
        "n_samples = 100\n",
        "\n",
        "\n",
        "\n",
        "# Test the smoothed classifier on an example image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test_smoothed_classifier(image, model, n_samples, sigma):\n",
        "    # Smooth the image using the model\n",
        "    smoothed_image = randomized_smoothing(image, model, n_samples, sigma)\n",
        "\n",
        "    # Get the predicted label from the smoothed image\n",
        "    smoothed_label = torch.argmax(smoothed_image).item()\n",
        "\n",
        "    # Get the confidence of the prediction\n",
        "    smoothed_confidence = smoothed_image.max().item()\n",
        "\n",
        "    # Plot the original and smoothed images side by side\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.imshow(image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(smoothed_image.cpu().squeeze().permute(1, 2, 0))\n",
        "    ax2.set_title(f'Smoothed Image (Label: {smoothed_label}, Confidence: {smoothed_confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "# Test the smoothed classifier on the example image\n",
        "test_smoothed_classifier(x, model, n_samples, sigma)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define the test set\n",
        "test_dataset = datasets.ImageNet(root='imagenet', split='val', transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "]))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "def evaluate_smoothed_classifier(model, test_loader, n_samples, sigma):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Smooth the images using the model\n",
        "        smoothed_images = randomized_smoothing(images, model, n_samples, sigma)\n",
        "\n",
        "        # Get the predicted labels from the smoothed images\n",
        "        smoothed_labels = torch.argmax(smoothed_images, dim=1)\n",
        "\n",
        "        # Compute the accuracy of the smoothed classifier\n",
        "        num_correct += (smoothed_labels == labels).sum().item()\n",
        "        num_total += labels.size(0)\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = evaluate_smoothed_classifier(model, test_loader, n_samples, sigma)\n",
        "print(f'Test Accuracy: {test_accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_lFTgLKbEzj"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxkJUxMYapTH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(pretrained=True).to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def randomized_smoothing(x, model, n_samples, noise_std):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = noise_std * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "url = 'https://upload.wikimedia.org/wikipedia/commons/3/32/Tom_Cruise_by_Gage_Skidmore.jpg'\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = img.resize((224, 224), resample=Image.BILINEAR)\n",
        "\n",
        "x = torch.tensor(np.array(img)).permute(2, 0, 1).unsqueeze(0).float().div(255).to(device)\n",
        "\n",
        "\n",
        "n_samples = 100\n",
        "noise_std = 0.1\n",
        "\n",
        "y_smooth = randomized_smoothing(x, model, n_samples, noise_std)\n",
        "pred_label = torch.argmax(y_smooth).item()\n",
        "\n",
        "print(f\"Predicted class: {pred_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cixok1QycKiA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the standard deviation of the Gaussian noise\n",
        "sigma = 0.1\n",
        "\n",
        "# Define the number of samples for randomized smoothing\n",
        "n_samples = 50\n",
        "\n",
        "# Define the batch size for evaluation\n",
        "batch_size = 64\n",
        "\n",
        "# Define the device to run the model on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the ImageNet dataset with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root='./imagenet/train', transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# Train a ResNet50 model on the dataset\n",
        "model = models.resnet50(pretrained=False).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "for epoch in range(10):\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Define the randomized smoothing function\n",
        "def smoothed_classifier(x, model, n_samples, sigma):\n",
        "    logits = torch.zeros((n_samples,) + model(x).shape).to(device)\n",
        "    for i in range(n_samples):\n",
        "        noise = sigma * torch.randn(x.shape).to(device)\n",
        "        logits[i] = model(x + noise)\n",
        "    avg_logits = torch.mean(logits, dim=0)\n",
        "    return F.softmax(avg_logits, dim=-1)\n",
        "\n",
        "# Evaluate the smoothed classifier on the test set\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "testset = torchvision.datasets.ImageFolder(root='./imagenet/val', transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "total, correct = 0, 0\n",
        "for i, (inputs, labels) in enumerate(testloader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = smoothed_classifier(inputs, model, n_samples, sigma)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the smoothed classifier on the test set: %.2f%%' % accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVO1YW3DRgTwl+EzCl/Ua6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}